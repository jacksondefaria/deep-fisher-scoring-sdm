{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da2e5b2",
   "metadata": {
    "papermill": {
     "duration": 0.012745,
     "end_time": "2022-10-07T05:01:20.217759",
     "exception": false,
     "start_time": "2022-10-07T05:01:20.205014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fisher FIFO\n",
    "\n",
    "In the `fisher-fifo-v3` notebook, we set a code to use the Fisher information effectively in neural netwrks using the *first-in-first-out* strategy to store gradients.\n",
    "\n",
    "Here our objective is to assess the effect of the FIFO buffer in the quality of the model. Also, we implement the partitioning strategy to make our algorithm generalizable to larger networks, as well as datasets with larger instances (like images).\n",
    "\n",
    "To enhance the partition effectiveness, we proceed to use the \"maximum-block-update\", to make the algorithm faster.\n",
    "\n",
    "---\n",
    "\n",
    "in fisher `fisher-fifo-v4` notebook we are trying to implement the algorithm in a more efficient way by using the [torch.bmm](https://pytorch.org/docs/stable/generated/torch.bmm.html). The main idea is to execute the matrix-multiplications of more than one block in an optimized way.\n",
    "\n",
    "---\n",
    "\n",
    "in `fisher-fifo-v4.2` notebook, we are trying to make the algorithm even faster using a single centralized object responsible for storing all the matrices (and their inverses) as well as all gradients and buffers. The main idea here is to make the most of vectorization using Pytorch utilities for GPU.\n",
    "\n",
    "---\n",
    "\n",
    "in `fisher-fifo-v4.3` notebook, we try to take the algorithm one step further in efficiency. We are implementing the strategy to retrieve the partitions in sets, instead of individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823f1464",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:20.242333Z",
     "iopub.status.busy": "2022-10-07T05:01:20.241661Z",
     "iopub.status.idle": "2022-10-07T05:01:21.825180Z",
     "shell.execute_reply": "2022-10-07T05:01:21.823757Z"
    },
    "papermill": {
     "duration": 1.599079,
     "end_time": "2022-10-07T05:01:21.828375",
     "exception": false,
     "start_time": "2022-10-07T05:01:20.229296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15d7a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:21.852351Z",
     "iopub.status.busy": "2022-10-07T05:01:21.851232Z",
     "iopub.status.idle": "2022-10-07T05:01:21.858251Z",
     "shell.execute_reply": "2022-10-07T05:01:21.856853Z"
    },
    "papermill": {
     "duration": 0.021337,
     "end_time": "2022-10-07T05:01:21.861019",
     "exception": false,
     "start_time": "2022-10-07T05:01:21.839682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d5e932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:21.884798Z",
     "iopub.status.busy": "2022-10-07T05:01:21.884474Z",
     "iopub.status.idle": "2022-10-07T05:01:24.114785Z",
     "shell.execute_reply": "2022-10-07T05:01:24.113444Z"
    },
    "papermill": {
     "duration": 2.245236,
     "end_time": "2022-10-07T05:01:24.117961",
     "exception": false,
     "start_time": "2022-10-07T05:01:21.872725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d812fbfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:24.141989Z",
     "iopub.status.busy": "2022-10-07T05:01:24.141146Z",
     "iopub.status.idle": "2022-10-07T05:01:24.148226Z",
     "shell.execute_reply": "2022-10-07T05:01:24.146859Z"
    },
    "papermill": {
     "duration": 0.022242,
     "end_time": "2022-10-07T05:01:24.151180",
     "exception": false,
     "start_time": "2022-10-07T05:01:24.128938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_device():    \n",
    "    if torch.cuda.is_available():\n",
    "\n",
    "        device = torch.device('cuda')\n",
    "        print( torch.cuda.get_device_name(device) )\n",
    "        print( torch.cuda.get_device_properties(device) )\n",
    "\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(device)\n",
    "        \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83264c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:24.174632Z",
     "iopub.status.busy": "2022-10-07T05:01:24.173653Z",
     "iopub.status.idle": "2022-10-07T05:01:38.293566Z",
     "shell.execute_reply": "2022-10-07T05:01:38.291958Z"
    },
    "papermill": {
     "duration": 14.135156,
     "end_time": "2022-10-07T05:01:38.296906",
     "exception": false,
     "start_time": "2022-10-07T05:01:24.161750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69026b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.322076Z",
     "iopub.status.busy": "2022-10-07T05:01:38.320903Z",
     "iopub.status.idle": "2022-10-07T05:01:38.421893Z",
     "shell.execute_reply": "2022-10-07T05:01:38.419644Z"
    },
    "papermill": {
     "duration": 0.115862,
     "end_time": "2022-10-07T05:01:38.424437",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.308575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-16GB\n",
      "_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"
     ]
    }
   ],
   "source": [
    "class cfg:\n",
    "    n_features = 28 * 28\n",
    "    # n_features = 7 * 7 # we use the resized mnist\n",
    "    \n",
    "    img_size = (32, 32)\n",
    "    img_channels = 1\n",
    "    n_classes = 10  ## we have 10 classes in MNIST\n",
    "    \n",
    "    # device = torch.device('cpu')\n",
    "    device = get_device()\n",
    "    \n",
    "    max_loss = 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a2d61",
   "metadata": {
    "papermill": {
     "duration": 0.010698,
     "end_time": "2022-10-07T05:01:38.446051",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.435353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338f0057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.470371Z",
     "iopub.status.busy": "2022-10-07T05:01:38.469317Z",
     "iopub.status.idle": "2022-10-07T05:01:38.478172Z",
     "shell.execute_reply": "2022-10-07T05:01:38.476835Z"
    },
    "papermill": {
     "duration": 0.023928,
     "end_time": "2022-10-07T05:01:38.480957",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.457029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dataset_mnist(batch_size):\n",
    "    print(f'generating MNIST data with {cfg.n_classes} classes')\n",
    "    \n",
    "    transf_ = torchvision.transforms.Compose([\n",
    "        # torchvision.transforms.Resize(size=[7, 7]),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transf_)\n",
    "    mnist_test  = datasets.MNIST(root='./data', train=False, download=True, transform=transf_)\n",
    "    \n",
    "    mnist_train_dataloader = DataLoader(dataset=mnist_train, batch_size=batch_size, shuffle=True)\n",
    "    mnist_test_dataloader  = DataLoader(dataset=mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return mnist_train_dataloader, mnist_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e32c2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.504685Z",
     "iopub.status.busy": "2022-10-07T05:01:38.503536Z",
     "iopub.status.idle": "2022-10-07T05:01:38.512021Z",
     "shell.execute_reply": "2022-10-07T05:01:38.510623Z"
    },
    "papermill": {
     "duration": 0.022686,
     "end_time": "2022-10-07T05:01:38.514665",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.491979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dataset_cifar10(batch_size):\n",
    "    print(f'generating CIFAR10 data with {cfg.n_classes} classes')\n",
    "    \n",
    "    transf_ = torchvision.transforms.Compose([\n",
    "        # torchvision.transforms.Resize(size=[14, 14]),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    cifar10_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transf_)\n",
    "    cifar10_test  = datasets.CIFAR10(root='./data', train=False, download=True, transform=transf_)\n",
    "    \n",
    "    cifar10_train_dataloader = DataLoader(dataset=cifar10_train, batch_size=batch_size, shuffle=True)\n",
    "    cifar10_test_dataloader  = DataLoader(dataset=cifar10_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return cifar10_train_dataloader, cifar10_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9962248e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.538117Z",
     "iopub.status.busy": "2022-10-07T05:01:38.537804Z",
     "iopub.status.idle": "2022-10-07T05:01:38.545124Z",
     "shell.execute_reply": "2022-10-07T05:01:38.543752Z"
    },
    "papermill": {
     "duration": 0.022171,
     "end_time": "2022-10-07T05:01:38.547886",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.525715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dataset_cifar100(batch_size):\n",
    "    print(f'generating CIFAR100 data with {cfg.n_classes} classes')\n",
    "    \n",
    "    transf_ = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    cifar100_train = datasets.CIFAR100(root='./data', train=True, download=True, transform=transf_)\n",
    "    cifar100_test  = datasets.CIFAR100(root='./data', train=False, download=True, transform=transf_)\n",
    "    \n",
    "    cifar100_train_dataloader = DataLoader(dataset=cifar100_train, batch_size=batch_size, shuffle=True)\n",
    "    cifar100_test_dataloader  = DataLoader(dataset=cifar100_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return cifar100_train_dataloader, cifar100_test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f87f2",
   "metadata": {
    "papermill": {
     "duration": 0.011099,
     "end_time": "2022-10-07T05:01:38.570222",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.559123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## declaring network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea4b85cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.594959Z",
     "iopub.status.busy": "2022-10-07T05:01:38.593742Z",
     "iopub.status.idle": "2022-10-07T05:01:38.602494Z",
     "shell.execute_reply": "2022-10-07T05:01:38.601158Z"
    },
    "papermill": {
     "duration": 0.023646,
     "end_time": "2022-10-07T05:01:38.605109",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.581463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_default_network(c=16, device=cfg.device):\n",
    "    net = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=cfg.n_features, out_features=c),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=c, out_features=c),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=c, out_features=c),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=c, out_features=cfg.n_classes)\n",
    "    )\n",
    "    \n",
    "    torchsummary.summary(net, input_size=[[cfg.n_features]], device='cpu')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed160219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.629565Z",
     "iopub.status.busy": "2022-10-07T05:01:38.629182Z",
     "iopub.status.idle": "2022-10-07T05:01:38.636664Z",
     "shell.execute_reply": "2022-10-07T05:01:38.635095Z"
    },
    "papermill": {
     "duration": 0.023159,
     "end_time": "2022-10-07T05:01:38.639612",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.616453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_MLP_network(device=cfg.device):\n",
    "    net = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=cfg.n_features, out_features=8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=8, out_features=16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=16, out_features=16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=16, out_features=cfg.n_classes)\n",
    "    )\n",
    "    \n",
    "    torchsummary.summary(net, input_size=[[cfg.n_features]], device='cpu')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46f6809a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.664431Z",
     "iopub.status.busy": "2022-10-07T05:01:38.663183Z",
     "iopub.status.idle": "2022-10-07T05:01:38.675464Z",
     "shell.execute_reply": "2022-10-07T05:01:38.674181Z"
    },
    "papermill": {
     "duration": 0.027375,
     "end_time": "2022-10-07T05:01:38.678125",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.650750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cnn_network(in_channels=cfg.img_channels, c=16, p_drop=0.1, device=cfg.device):\n",
    "    \n",
    "    img_flat_size = (4 * c * (cfg.img_size[0] // 8) * (cfg.img_size[1] // 8) )\n",
    "    print(img_flat_size)\n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=c, kernel_size=5, stride=2, padding=2),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Conv2d(in_channels=c, out_channels=(2 * c), kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout2d(p=p_drop),\n",
    "        \n",
    "        nn.Conv2d(in_channels=(2 * c), out_channels=(4 * c), kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout2d(p=p_drop),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        \n",
    "        nn.Linear(in_features=img_flat_size, out_features=(8 * c) ),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=p_drop),\n",
    "        \n",
    "        nn.Linear(in_features=(8 * c), out_features=(4 * c) ),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=p_drop),\n",
    "        \n",
    "        nn.Linear(in_features=(4 * c), out_features=cfg.n_classes)\n",
    "    )\n",
    "    \n",
    "    torchsummary.summary(net, input_size=[[cfg.img_channels, *cfg.img_size]], device='cpu')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ecf430d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.701647Z",
     "iopub.status.busy": "2022-10-07T05:01:38.701316Z",
     "iopub.status.idle": "2022-10-07T05:01:38.711876Z",
     "shell.execute_reply": "2022-10-07T05:01:38.710432Z"
    },
    "papermill": {
     "duration": 0.025322,
     "end_time": "2022-10-07T05:01:38.714564",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.689242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cnn_network_v2(in_channels=cfg.img_channels, p_drop=0.1, device=cfg.device):\n",
    "    \n",
    "    net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=96, kernel_size=5, padding=2),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Conv2d(in_channels=96, out_channels=80, kernel_size=5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.Dropout2d(p=p_drop),\n",
    "        \n",
    "        nn.Conv2d(in_channels=80, out_channels=96, kernel_size=5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(p=p_drop),\n",
    "        \n",
    "        nn.Conv2d(in_channels=96, out_channels=64, kernel_size=5, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(p=p_drop),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        \n",
    "        # nn.Linear(in_features=4096, out_features=256 ),\n",
    "        nn.Linear(in_features=(cfg.img_size[0] // 4) * (cfg.img_size[1] // 4) * 64, out_features=256 ),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=p_drop),\n",
    "        \n",
    "        nn.Linear(in_features=256, out_features=cfg.n_classes)\n",
    "    )\n",
    "    \n",
    "    torchsummary.summary(net, input_size=[[cfg.img_channels, *cfg.img_size]], device='cpu')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b5214b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.739311Z",
     "iopub.status.busy": "2022-10-07T05:01:38.738048Z",
     "iopub.status.idle": "2022-10-07T05:01:38.745205Z",
     "shell.execute_reply": "2022-10-07T05:01:38.744011Z"
    },
    "papermill": {
     "duration": 0.022151,
     "end_time": "2022-10-07T05:01:38.747919",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.725768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_resnet18(device=cfg.device):\n",
    "    \n",
    "    net = torchvision.models.resnet18(num_classes=cfg.n_classes)\n",
    "    torchsummary.summary(net, input_size=[[cfg.img_channels, *cfg.img_size]], device='cpu')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fff20",
   "metadata": {
    "papermill": {
     "duration": 0.011176,
     "end_time": "2022-10-07T05:01:38.770236",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.759060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# object for calculation of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97e14e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.794638Z",
     "iopub.status.busy": "2022-10-07T05:01:38.793652Z",
     "iopub.status.idle": "2022-10-07T05:01:38.805724Z",
     "shell.execute_reply": "2022-10-07T05:01:38.804506Z"
    },
    "papermill": {
     "duration": 0.027381,
     "end_time": "2022-10-07T05:01:38.808832",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.781451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metrics():\n",
    "    def __init__(self, value_round=None, time_round=None):\n",
    "        self.metrics_dict = {}\n",
    "        self.set_initial_time()\n",
    "        self.val_round = value_round\n",
    "        self.time_round = time_round\n",
    "        \n",
    "    def set_initial_time(self):\n",
    "        self.init_time = time.time()\n",
    "        \n",
    "    def get_time(self):\n",
    "        return time.time() - self.init_time\n",
    "    \n",
    "    def add(self, key, value, step=None):\n",
    "        \n",
    "        if step is None:\n",
    "            step = np.nan\n",
    "        \n",
    "        if key not in self.metrics_dict:\n",
    "            self.metrics_dict[key] = []\n",
    "        \n",
    "        t = self.get_time()\n",
    "        if self.time_round is not None:\n",
    "            t = round(t, ndigits=self.time_round)\n",
    "        \n",
    "        if self.val_round is not None:\n",
    "            value = round(value, ndigits=self.val_round)\n",
    "        \n",
    "        self.metrics_dict[key].append( (value, step, t) )\n",
    "    \n",
    "    def add_(self, dict_, step=None):\n",
    "        for key, value in dict_.items():\n",
    "            self.add(key, value, step)\n",
    "    \n",
    "    def get(self, key, get_step=False, get_time=False):\n",
    "        y, x, t = zip(*self.metrics_dict[key])\n",
    "        y, x, t = list(y), list(x), list(t)\n",
    "        \n",
    "        return x, y, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8c166",
   "metadata": {
    "papermill": {
     "duration": 0.011001,
     "end_time": "2022-10-07T05:01:38.830863",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.819862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fisher Information calculation objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e724c5bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.854779Z",
     "iopub.status.busy": "2022-10-07T05:01:38.854476Z",
     "iopub.status.idle": "2022-10-07T05:01:38.889711Z",
     "shell.execute_reply": "2022-10-07T05:01:38.888473Z"
    },
    "papermill": {
     "duration": 0.05066,
     "end_time": "2022-10-07T05:01:38.892412",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.841752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FisherFIFO():\n",
    "    def __init__(self,\n",
    "                 named_params,\n",
    "                 buffer_size,\n",
    "                 partition_size,\n",
    "                 block_updates):\n",
    "        \n",
    "        self.buffer_size = buffer_size\n",
    "        self.partition_size = partition_size\n",
    "        self.block_updates = block_updates\n",
    "        \n",
    "        named_params = list(named_params)\n",
    "        \n",
    "        self.partition_fisher_list = []\n",
    "        total_partitions, total_block_upd = 0, 0\n",
    "        for pi, (n, p) in enumerate( named_params ):\n",
    "            part_fisher = PartitionerFisherFIFO(param = p,\n",
    "                                                name = n,\n",
    "                                                buffer_size = buffer_size,\n",
    "                                                partition_size = partition_size,\n",
    "                                                block_updates = block_updates,\n",
    "                                                parent_fifo = None)\n",
    "            \n",
    "            self.partition_fisher_list.append( (p, part_fisher, total_partitions, total_block_upd) )\n",
    "            \n",
    "            total_partitions += part_fisher.num_part\n",
    "            total_block_upd += part_fisher.block_updates\n",
    "            \n",
    "        self.num_part = total_partitions\n",
    "        self.total_block_updates = total_block_upd\n",
    "        \n",
    "        print(f'total partitions: {self.num_part} - effective block updates: {self.total_block_updates}')\n",
    "        \n",
    "        ## pre-alocate the memory for the tensor that stores the selected gradients (changes every iteration)\n",
    "        self.g = torch.zeros(size=[self.total_block_updates, partition_size, 1], dtype=torch.float, device=cfg.device)\n",
    "        \n",
    "        ## pre-alocate the memory for the tensor that stores the buffer and the tensor for the inverse\n",
    "        self.buffer = torch.zeros(size=[self.num_part, partition_size, buffer_size], dtype=torch.float, device=cfg.device)\n",
    "        self.fisher_inv = torch.zeros(size=[self.num_part, partition_size, partition_size], dtype=torch.float, device=cfg.device)        \n",
    "    \n",
    "        print('initializing buffers and inverses...')\n",
    "        ## now we initialize the buffer and the inverse for all partitions\n",
    "        i = 0\n",
    "        for _, part_fisher, _, _ in self.partition_fisher_list:\n",
    "            for _, start, end in part_fisher.ind_fisher_list:\n",
    "\n",
    "                if i == 0 or ( (i + 1) % 10000 ) == 0 or i == (self.num_part - 1):\n",
    "                    print(f'partition {i+1}/{self.num_part}')\n",
    "\n",
    "                n = end - start\n",
    "                buffer, _, fisher_inv = self.initialize_fisher_partition(param_size=n, buffer_size=self.buffer_size)\n",
    "\n",
    "                self.buffer[i, :n, :] = buffer\n",
    "                self.fisher_inv[i, :n, :n] = fisher_inv\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    \n",
    "    def initialize_fisher_partition(self, param_size, buffer_size):\n",
    "        \n",
    "        buffer = self.get_initial_buffer_v2(param_size, buffer_size)\n",
    "            \n",
    "        ## shuffle buffer across columns\n",
    "        buffer = buffer[:, torch.randperm(buffer.shape[1]) ]\n",
    "        \n",
    "        ## the fisher matrix will be initialized as G @ G.T, in which G is our buffer. We built\n",
    "        ## our buffer in a smart way so the resulting Fisher info matrix is initialized close to identity\n",
    "        fisher = buffer @ buffer.T\n",
    "        \n",
    "        ## since our Fisher information is diagonal for now, its inverse is given just by the innverted\n",
    "        ## elements of the diagonal. \n",
    "        fisher_inv = torch.diag( 1 / torch.diag(fisher) )\n",
    "        \n",
    "        return buffer, fisher, fisher_inv\n",
    "    \n",
    "    \n",
    "    def get_initial_buffer_v2(self, param_size, buffer_size):\n",
    "        ## here we adopt a faster approach to initialize the buffer. We use n \n",
    "        ## identity matrices concatenated column-wise. n is determined by `param_size` and `buffer_size`\n",
    "        \n",
    "        n_eye = math.ceil(buffer_size / param_size)\n",
    "        I = torch.eye(n=param_size, dtype=torch.float, device=cfg.device)\n",
    "        \n",
    "        buffer = torch.cat(n_eye * [I], dim=1)[:, :buffer_size]\n",
    "        \n",
    "        assert buffer.shape == (param_size, buffer_size)\n",
    "        \n",
    "        return buffer\n",
    "\n",
    "\n",
    "    def get_idx_lists(self):\n",
    "        run_enc_list = []\n",
    "        default_idx_list = []\n",
    "        for p, part_fisher, num_part, block_upd in self.partition_fisher_list:\n",
    "            init_block, end_block, g_init_idx, g_end_idx = part_fisher.get_random_blocks()\n",
    "            \n",
    "            # print(f'param shape: {p.shape} - blocks: {init_block} to {end_block} - grad: {g_init_idx} to {g_end_idx}')\n",
    "            \n",
    "            run_enc_list.append( (num_part + init_block, num_part + end_block, g_init_idx, g_end_idx) )\n",
    "            default_idx_list.append( np.arange(start=num_part + init_block, stop=num_part + end_block + 1) )\n",
    "            \n",
    "            \n",
    "        return run_enc_list, np.concatenate(default_idx_list)\n",
    "    \n",
    "    \n",
    "    def read_gradients(self, idx):\n",
    "        self_g_start = 0\n",
    "        for i, (_, _, g_start, g_end) in enumerate(idx):\n",
    "            n_grad = g_end - g_start\n",
    "            # self_g_end = min( self_g_start + n_grad, torch.numel(self.g) )\n",
    "            self_g_end = self_g_start + n_grad\n",
    "            \n",
    "            p, _, _, _ = self.partition_fisher_list[i]\n",
    "            \n",
    "            self.g.view(-1)[self_g_start:self_g_end] = p.grad.view(-1)[g_start:g_end]\n",
    "            \n",
    "            if (n_grad % self.partition_size) > 0:\n",
    "                extra_zeros = self.partition_size - (n_grad % self.partition_size)\n",
    "                self.g.view(-1)[self_g_end:(self_g_end + extra_zeros)] = 0.0\n",
    "            else:\n",
    "                extra_zeros = 0\n",
    "            \n",
    "#             print(f'self_g_start: {self_g_start} - self_g_end: {self_g_end} - self.g.shape: {self.g.view(-1).shape}')\n",
    "#             print(f'g_start: {g_start} - g_end: {g_end} - p.grad.shape: {p.grad.view(-1).shape}')\n",
    "#             print(f'n_grad: {n_grad} - part-size: {self.partition_size} - extra-zeros: {extra_zeros}')\n",
    "#             print()\n",
    "            \n",
    "            self_g_start = self_g_end + extra_zeros\n",
    "            \n",
    "\n",
    "    def write_gradients(self, idx):\n",
    "        self_g_start = 0\n",
    "        for i, (_, _, g_start, g_end) in enumerate(idx):\n",
    "            n_grad = g_end - g_start\n",
    "            self_g_end = self_g_start + n_grad\n",
    "            \n",
    "            p, _, _, _ = self.partition_fisher_list[i]\n",
    "            p.grad.view(-1)[g_start:g_end] = self.g.view(-1)[self_g_start:self_g_end]\n",
    "\n",
    "            if (n_grad % self.partition_size) > 0:\n",
    "                extra_zeros = self.partition_size - (n_grad % self.partition_size)\n",
    "            else:\n",
    "                extra_zeros = 0\n",
    "            \n",
    "            self_g_start = self_g_end + extra_zeros\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        ## selects the blocks to be updated\n",
    "        run_enc_idx, default_idx = self.get_idx_lists()\n",
    "        \n",
    "        ## read the selected blocks gradients and stores them in self.g\n",
    "        self.read_gradients(run_enc_idx)\n",
    "        \n",
    "        ## get apart the inverses and buffers for the selected blocks\n",
    "        inv = self.fisher_inv[default_idx, ...]\n",
    "        buffer = self.buffer[default_idx, ...]\n",
    "        \n",
    "        # print(inv.shape, buffer.shape)\n",
    "        \n",
    "        ## update the buffer\n",
    "        \n",
    "        ## dimensions are: partitions, gradient-size, bufffer-size\n",
    "        g_old = buffer[:, :, 0:1] \n",
    "        \n",
    "        ## we  update in the third dimension: \"buffer-size\"\n",
    "        buffer = torch.cat([buffer[:, :, 1:], self.g], dim=2)\n",
    "        \n",
    "        ## update the inverses and modify current gradients\n",
    "        ## ...\n",
    "        sqrt_NB = math.sqrt(self.buffer_size)\n",
    "        \n",
    "        ## update inverse - phase 1: add new gradient ##\n",
    "        g_phase1 = self.upd_inverse( (1 / sqrt_NB) * self.g, inv, type_='sum')\n",
    "\n",
    "        ## update inverse - phase 2: remove old gradient ##\n",
    "        self.upd_inverse( (1 / sqrt_NB) * g_old, inv, type_='sub')\n",
    "\n",
    "        ## modify the current gradients\n",
    "        if False:\n",
    "            ## use the \"phase-1-trick\" to get the estimated new gradient\n",
    "            self.g = g_phase1 * sqrt_NB\n",
    "        else:\n",
    "            ## get the modified gradient using \"de facto\" the new inverses and the gradients\n",
    "            self.g = self.modify_grad(self.g, inv)\n",
    "        \n",
    "        ## return the inverses and buffers to the main tensor\n",
    "        self.fisher_inv[default_idx, ...] = inv\n",
    "        self.buffer[default_idx, ...] = buffer\n",
    "        \n",
    "        ## return the modified gradients to the parameters\n",
    "        self.write_gradients(run_enc_idx)\n",
    "\n",
    "\n",
    "    def upd_inverse(self, g, inverse, type_='sum'):\n",
    "        ## update the inverse based on the woodbury inversion\n",
    "        f_inv_g = torch.bmm(inverse, g)\n",
    "\n",
    "        if type_ == 'sum':\n",
    "            d = 1 + torch.sum(g * f_inv_g, dim=[1, 2], keepdim=True)\n",
    "            inverse[:] = inverse - (f_inv_g * torch.transpose(f_inv_g, 1, 2) / d)\n",
    "\n",
    "        elif type_ == 'sub':\n",
    "            d = 1 - torch.sum(g * f_inv_g, dim=[1, 2], keepdim=True)\n",
    "            inverse[:] = inverse + (f_inv_g * torch.transpose(f_inv_g, 1, 2) / d)\n",
    "\n",
    "        else:\n",
    "            ## incorrect type\n",
    "            print('incorrect rank-1 update type: ' + type_)\n",
    "        \n",
    "        return f_inv_g\n",
    "\n",
    "\n",
    "    def modify_grad(self, g, inverse):\n",
    "        return torch.bmm(inverse, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23613903",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.916992Z",
     "iopub.status.busy": "2022-10-07T05:01:38.915895Z",
     "iopub.status.idle": "2022-10-07T05:01:38.928353Z",
     "shell.execute_reply": "2022-10-07T05:01:38.927174Z"
    },
    "papermill": {
     "duration": 0.027403,
     "end_time": "2022-10-07T05:01:38.931050",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.903647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PartitionerFisherFIFO():\n",
    "    def __init__(self,\n",
    "                 param,\n",
    "                 name,\n",
    "                 buffer_size,\n",
    "                 partition_size,\n",
    "                 block_updates,\n",
    "                 parent_fifo):\n",
    "        \n",
    "        self.param = param\n",
    "        self.name = name \n",
    "        \n",
    "        if partition_size is None:\n",
    "            self.partition_size = param.numel()\n",
    "        else:\n",
    "            self.partition_size = partition_size\n",
    "        \n",
    "        ## calculates the number of partitions required. It is calculated using the param size and\n",
    "        ## our partition maximum size. The gradient (the same size as param) is going to be partitioned in\n",
    "        ## equal pieces (except possibly the last one) to be processed individually by our \"IndividualFisherFIFO\"\n",
    "        self.param_size = param.numel()\n",
    "        self.num_part = math.ceil(self.param_size / self.partition_size)\n",
    "        \n",
    "        ## the number of blocks (partitions) to update at each iteration. This can be < num_part to make\n",
    "        ## the algorithm more efficient. (we dont update every partition at every iteration)\n",
    "        if block_updates is None:\n",
    "            self.block_updates = self.num_part\n",
    "        else:\n",
    "            self.block_updates = min(block_updates, self.num_part)\n",
    "        \n",
    "        print(f'FisherPartitioner: param: {self.param_size} - partition: {self.partition_size} - nº part: {self.num_part} - block updates: {self.block_updates}')\n",
    "                \n",
    "        ## the list stores the indexes used to partition the gradient\n",
    "        self.ind_fisher_list = []\n",
    "        for i in range(self.num_part):\n",
    "            start = i * self.partition_size\n",
    "            end = min(start + self.partition_size, self.param_size)\n",
    "            \n",
    "            self.ind_fisher_list.append( (i, start, end) )\n",
    "        \n",
    "    \n",
    "    def get_random_blocks(self, num_part=None, block_upd=None):\n",
    "        \n",
    "        if num_part is None:\n",
    "            num_part = self.num_part\n",
    "        \n",
    "        if block_upd is None:\n",
    "            block_upd = self.block_updates\n",
    "        \n",
    "        ## choose the initial block randomly\n",
    "        init_block = np.random.choice(num_part - block_upd + 1)\n",
    "        \n",
    "        ## the final block will be necessarily `block_upd` blocks further. This means we select\n",
    "        ## a contiguous sequence of blocks. This is going to be used for performance reasons\n",
    "        end_block = init_block + block_upd - 1\n",
    "        \n",
    "        ## therefore, the starting and ending index to be used to fetch the gradient positions for the\n",
    "        ## blocks will be the starting index for the first block and the ending positions for the last block\n",
    "        _, g_init_idx, _ = self.ind_fisher_list[init_block]\n",
    "        _, _, g_end_idx = self.ind_fisher_list[end_block]\n",
    "        \n",
    "        return init_block, end_block, g_init_idx, g_end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024f0875",
   "metadata": {
    "papermill": {
     "duration": 0.010596,
     "end_time": "2022-10-07T05:01:38.952431",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.941835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ceee34",
   "metadata": {
    "papermill": {
     "duration": 0.010444,
     "end_time": "2022-10-07T05:01:38.973768",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.963324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# utils function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04b0ede8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:38.997093Z",
     "iopub.status.busy": "2022-10-07T05:01:38.996707Z",
     "iopub.status.idle": "2022-10-07T05:01:39.002136Z",
     "shell.execute_reply": "2022-10-07T05:01:39.000705Z"
    },
    "papermill": {
     "duration": 0.019993,
     "end_time": "2022-10-07T05:01:39.004678",
     "exception": false,
     "start_time": "2022-10-07T05:01:38.984685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_score_tns(y_true, y_pred):\n",
    "    return torch.mean( (y_true == y_pred).to(dtype=torch.float) ).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d10687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.029444Z",
     "iopub.status.busy": "2022-10-07T05:01:39.028227Z",
     "iopub.status.idle": "2022-10-07T05:01:39.036320Z",
     "shell.execute_reply": "2022-10-07T05:01:39.035235Z"
    },
    "papermill": {
     "duration": 0.022737,
     "end_time": "2022-10-07T05:01:39.039066",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.016329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_iteration(x, y, net, optim, loss, fisher=None):\n",
    "    net.train()\n",
    "    net.zero_grad()\n",
    "    \n",
    "    y_pred = net(x)\n",
    "    l = loss(y_pred, y)\n",
    "    \n",
    "    l.backward()\n",
    "    \n",
    "    if fisher is not None:\n",
    "        fisher.step()\n",
    "    \n",
    "    optim.step()\n",
    "    \n",
    "    return l.item(), accuracy_score_tns( y.view(-1), y_pred.argmax(dim=1).view(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87973a1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.063679Z",
     "iopub.status.busy": "2022-10-07T05:01:39.063358Z",
     "iopub.status.idle": "2022-10-07T05:01:39.071625Z",
     "shell.execute_reply": "2022-10-07T05:01:39.070182Z"
    },
    "papermill": {
     "duration": 0.022568,
     "end_time": "2022-10-07T05:01:39.074011",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.051443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(net, dataloader, loss):\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        loss_list = []\n",
    "        y_pred_list = []\n",
    "        y_label_list = []\n",
    "        for x, y in dataloader:\n",
    "            \n",
    "            x = x.to(cfg.device)\n",
    "            y = y.to(cfg.device)\n",
    "\n",
    "            y_pred = net(x)\n",
    "            l = loss(y_pred, y)\n",
    "\n",
    "            loss_list.append( l.cpu().item() )\n",
    "            y_pred_list.append( y_pred.argmax(dim=1).view(-1) )\n",
    "            y_label_list.append( y.view(-1) )\n",
    "\n",
    "        y_pred_list = torch.cat(y_pred_list).view(-1)\n",
    "        y_label_list = torch.cat(y_label_list).view(-1)\n",
    "\n",
    "    return np.mean(loss_list), accuracy_score_tns(y_label_list, y_pred_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f5f96",
   "metadata": {
    "papermill": {
     "duration": 0.010777,
     "end_time": "2022-10-07T05:01:39.096332",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.085555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48e3dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.119854Z",
     "iopub.status.busy": "2022-10-07T05:01:39.119520Z",
     "iopub.status.idle": "2022-10-07T05:01:39.139008Z",
     "shell.execute_reply": "2022-10-07T05:01:39.137666Z"
    },
    "papermill": {
     "duration": 0.034571,
     "end_time": "2022-10-07T05:01:39.141654",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.107083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_network_fisher_optimization(batch_size = 32,\n",
    "                                      lr = 1e-3,\n",
    "                                      momentum = 0.9,\n",
    "                                      epochs = 30,\n",
    "                                      buffer_size = 1000,\n",
    "                                      partition_size = 256,\n",
    "                                      block_updates = 4,\n",
    "                                      net_params = {'c':16, 'p':0.1},\n",
    "                                      apply_fisher = True,\n",
    "                                      # gpu_memory_check = 20,\n",
    "                                      time_limit_secs = 600,\n",
    "                                      interval_print = 100):\n",
    "\n",
    "    ## declare (instantiate) the dataset\n",
    "    # train_dataloader, test_dataloader = generate_dataset_cifar10(batch_size = batch_size)\n",
    "    train_dataloader, test_dataloader = generate_dataset_mnist(batch_size = batch_size)\n",
    "    # train_dataloader, test_dataloader = generate_dataset_cifar100(batch_size = batch_size)\n",
    "\n",
    "    ## instantiate the network\n",
    "    # net = get_cnn_network_v2(p_drop = net_params['p']).to(device=cfg.device)\n",
    "    # net = get_resnet18().to(device=cfg.device)\n",
    "    # net = get_MLP_network().to(device=cfg.device)\n",
    "    net = get_default_network().to(device=cfg.device)\n",
    "    \n",
    "    if apply_fisher:\n",
    "        ## instantiate FisherFIFO object to create and update the Fisher info matrix\n",
    "        fisher_fifo = FisherFIFO(named_params = net.named_parameters(),\n",
    "                                 buffer_size = buffer_size,\n",
    "                                 partition_size = partition_size,\n",
    "                                 block_updates = block_updates)\n",
    "    else:\n",
    "        fisher_fifo = None\n",
    "\n",
    "    ## create loss object: we multiply by our constant to stabilize norms\n",
    "    # cross_entropy = nn.CrossEntropyLoss(reduction='mean') # standard version\n",
    "    cross_entropy_standard = nn.CrossEntropyLoss(reduction='mean')\n",
    "    cross_entropy = lambda y_pred, y: math.sqrt(batch_size) * cross_entropy_standard(y_pred, y)\n",
    "    \n",
    "    ## create optimize objects\n",
    "    optim = torch.optim.SGD(params=net.parameters(), lr=lr, momentum=momentum)\n",
    "    # optim = torch.optim.SGD(params=net.parameters(), lr=lr)\n",
    "\n",
    "    default_metrics = Metrics(value_round=3, time_round=2)\n",
    "\n",
    "    ini_time = time.time()\n",
    "\n",
    "    step = 0\n",
    "    training_finished = False\n",
    "    for epc in range(1, epochs + 1):\n",
    "        \n",
    "        if training_finished:\n",
    "            break\n",
    "        \n",
    "        print(f'starting epoch: {epc}/{epochs}')\n",
    "\n",
    "        for nbt, (x, y) in enumerate(train_dataloader):\n",
    "\n",
    "            if training_finished:\n",
    "                break\n",
    "\n",
    "            x = x.to(cfg.device)\n",
    "            y = y.to(cfg.device)\n",
    "\n",
    "            train_loss, train_acc = train_iteration(x, y, net, optim, cross_entropy, fisher_fifo)\n",
    "            default_metrics.add_({'train-loss': train_loss, 'train-acc': train_acc}, step=step)\n",
    "            \n",
    "            ## check time limit\n",
    "            t = int(time.time() - ini_time)\n",
    "            if t > time_limit_secs:\n",
    "                print('time is up! finishing training')\n",
    "                training_finished = True\n",
    "\n",
    "            if ( (nbt + 1) % interval_print ) == 0 or (nbt + 1) == len(train_dataloader) or training_finished:\n",
    "                avg_train_loss = np.mean( default_metrics.get('train-loss')[1][-interval_print:] )\n",
    "                avg_train_acc = np.mean( default_metrics.get('train-acc')[1][-interval_print:] )\n",
    "                \n",
    "                test_loss, test_acc = evaluate(net, test_dataloader, cross_entropy)\n",
    "                default_metrics.add_({'test-loss': test_loss, 'test-acc': test_acc}, step=step)\n",
    "\n",
    "                m, s = t // 60, t % 60\n",
    "\n",
    "                print(f'batch: {nbt + 1}/{len(train_dataloader)}', end='')\n",
    "                print(f' - train loss: {avg_train_loss:.4f} - test loss: {test_loss:.4f}', end='')\n",
    "                print(f' - train acc: {avg_train_acc:.4f} - test acc: {test_acc:.4f}', end='')\n",
    "                print(f' - {m}m {s}s')\n",
    "                \n",
    "            step += 1\n",
    "\n",
    "        ## check for GPU memory consumption\n",
    "        if torch.cuda.is_available():\n",
    "            mem_alloc_gb = torch.cuda.memory_allocated(cfg.device) / 1024**3\n",
    "            mem_res_gb = torch.cuda.memory_reserved(cfg.device) / 1024**3\n",
    "            max_mem_alloc_gb = torch.cuda.max_memory_allocated(cfg.device) / 1024**3\n",
    "            max_mem_res_gb = torch.cuda.max_memory_reserved(cfg.device) / 1024**3\n",
    "\n",
    "            print(f'GPU memory used: {mem_alloc_gb:.2f} GB - max: {max_mem_alloc_gb:.2f} GB - memory reserved: {mem_res_gb:.2f} GB - max: {max_mem_res_gb:.2f} GB')\n",
    "\n",
    "            # torch.cuda.empty_cache()\n",
    "\n",
    "    return default_metrics, fisher_fifo, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2707648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.165683Z",
     "iopub.status.busy": "2022-10-07T05:01:39.164561Z",
     "iopub.status.idle": "2022-10-07T05:01:39.170357Z",
     "shell.execute_reply": "2022-10-07T05:01:39.169257Z"
    },
    "papermill": {
     "duration": 0.020406,
     "end_time": "2022-10-07T05:01:39.172949",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.152543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_network_fisher_optimization(apply_fisher = True,\n",
    "#                                    buffer_size = 32,\n",
    "#                                    partition_size = 16,\n",
    "#                                    block_updates = 100,\n",
    "#                                    net_params = {'p': 0.1},\n",
    "#                                    epochs = 10,\n",
    "#                                    time_limit_secs = 15 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c248457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.198253Z",
     "iopub.status.busy": "2022-10-07T05:01:39.197089Z",
     "iopub.status.idle": "2022-10-07T05:01:39.202951Z",
     "shell.execute_reply": "2022-10-07T05:01:39.201717Z"
    },
    "papermill": {
     "duration": 0.021166,
     "end_time": "2022-10-07T05:01:39.205639",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.184473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net = torchvision.models.resnet18()\n",
    "# torchsummary.summary(net, input_size=[[3, 64, 64]], device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60e036f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.230214Z",
     "iopub.status.busy": "2022-10-07T05:01:39.228974Z",
     "iopub.status.idle": "2022-10-07T05:01:39.238550Z",
     "shell.execute_reply": "2022-10-07T05:01:39.237322Z"
    },
    "papermill": {
     "duration": 0.024285,
     "end_time": "2022-10-07T05:01:39.241141",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.216856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_step_saved = None\n",
    "\n",
    "def results_list_to_json(results_list, out_dir='/kaggle/working', step=0):\n",
    "    global last_step_saved\n",
    "\n",
    "    json_results = []\n",
    "\n",
    "    for metrics, bs, ps, bu in results_list:\n",
    "        json_results.append({\n",
    "            'buffer-size': bs,\n",
    "            'partition-size': ps,\n",
    "            'blocks-updates': bu,\n",
    "            'metrics': metrics.metrics_dict\n",
    "        })\n",
    "\n",
    "    with open( os.path.join(out_dir, f'results_step_{step}.json'), 'w' ) as fp:\n",
    "        json.dump(json_results, fp)\n",
    "    \n",
    "    if last_step_saved is not None:\n",
    "        old_file = os.path.join(out_dir, f'results_step_{last_step_saved}.json')\n",
    "        if os.path.exists(old_file):\n",
    "            os.remove(old_file)\n",
    "    \n",
    "    last_step_saved = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b165af7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.263819Z",
     "iopub.status.busy": "2022-10-07T05:01:39.263390Z",
     "iopub.status.idle": "2022-10-07T05:01:39.269855Z",
     "shell.execute_reply": "2022-10-07T05:01:39.268293Z"
    },
    "papermill": {
     "duration": 0.020905,
     "end_time": "2022-10-07T05:01:39.272738",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.251833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_min_test_loss(metrics):\n",
    "    _, test_loss, _ = metrics.get('test-loss')\n",
    "    return min(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f7303",
   "metadata": {
    "papermill": {
     "duration": 0.010542,
     "end_time": "2022-10-07T05:01:39.293969",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.283427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## varying buffer-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a13ef4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.317705Z",
     "iopub.status.busy": "2022-10-07T05:01:39.316638Z",
     "iopub.status.idle": "2022-10-07T05:01:39.322879Z",
     "shell.execute_reply": "2022-10-07T05:01:39.321478Z"
    },
    "papermill": {
     "duration": 0.021042,
     "end_time": "2022-10-07T05:01:39.325761",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.304719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # buffer_size = 64\n",
    "# partition_size = 32\n",
    "# block_updates = 16\n",
    "\n",
    "# results_list = []\n",
    "# step_i = 0\n",
    "\n",
    "# for buffer_size in [32, 64, 128, 256, 512]:\n",
    "    \n",
    "#     print()\n",
    "#     print('-----------------------------------')\n",
    "#     print(f'testing: partition-size: {partition_size} - buffer-size: {buffer_size} - block_updates: {block_updates}')\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "#     default_metrics, _, _ = train_network_fisher_optimization(apply_fisher = True,\n",
    "#                                                            buffer_size = buffer_size,\n",
    "#                                                            partition_size = partition_size,\n",
    "#                                                            block_updates = block_updates,\n",
    "#                                                            epochs = 10,\n",
    "#                                                            time_limit_secs = 5 * 60)\n",
    "    \n",
    "#     results_list.append( (default_metrics, buffer_size, partition_size, block_updates) )\n",
    "#     results_list_to_json(results_list, step=step_i)\n",
    "#     step_i += 1\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe03241",
   "metadata": {
    "papermill": {
     "duration": 0.010717,
     "end_time": "2022-10-07T05:01:39.347326",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.336609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## varying partition size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e7f2a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.370801Z",
     "iopub.status.busy": "2022-10-07T05:01:39.370441Z",
     "iopub.status.idle": "2022-10-07T05:01:39.376567Z",
     "shell.execute_reply": "2022-10-07T05:01:39.375310Z"
    },
    "papermill": {
     "duration": 0.021276,
     "end_time": "2022-10-07T05:01:39.379790",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.358514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # buffer_size = 64\n",
    "# # partition_size = 32\n",
    "# block_updates = 1024\n",
    "\n",
    "# results_list = []\n",
    "# step_i = 0\n",
    "\n",
    "# for i, partition_size in enumerate([2, 8, 32, 128, 512, 2048]):\n",
    "    \n",
    "#     buffer_size = partition_size\n",
    "#     bu = int(block_updates // 2**i)\n",
    "    \n",
    "#     print()\n",
    "#     print('-----------------------------------')\n",
    "#     print(f'testing: partition-size: {partition_size} - buffer-size: {buffer_size} - block_updates: {bu}')\n",
    "    \n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "#     default_metrics, _, _ = train_network_fisher_optimization(apply_fisher = True,\n",
    "#                                                            buffer_size = buffer_size,\n",
    "#                                                            partition_size = partition_size,\n",
    "#                                                            block_updates = bu,\n",
    "#                                                            epochs = 10,\n",
    "#                                                            time_limit_secs = 5 * 60)\n",
    "    \n",
    "#     results_list.append( (default_metrics, buffer_size, partition_size, bu) )\n",
    "#     results_list_to_json(results_list, step=step_i)\n",
    "#     step_i += 1\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2328f13",
   "metadata": {
    "papermill": {
     "duration": 0.010504,
     "end_time": "2022-10-07T05:01:39.401789",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.391285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## varying block-updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f53f929b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T05:01:39.425509Z",
     "iopub.status.busy": "2022-10-07T05:01:39.425156Z",
     "iopub.status.idle": "2022-10-07T05:32:10.500078Z",
     "shell.execute_reply": "2022-10-07T05:32:10.498518Z"
    },
    "papermill": {
     "duration": 1831.09067,
     "end_time": "2022-10-07T05:32:10.503768",
     "exception": false,
     "start_time": "2022-10-07T05:01:39.413098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------\n",
      "testing: partition-size: 32 - buffer-size: 64 - block_updates: 2\n",
      "generating MNIST data with 10 classes\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd58a9324f74204aac0210a7afa9e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041963780b644974b6112ec113c06287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b5ecc4fb814edb8524e54c36f61539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c63573449ab453eb0d8b055941b1a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 16]          12,560\n",
      "              ReLU-3                   [-1, 16]               0\n",
      "            Linear-4                   [-1, 16]             272\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "            Linear-6                   [-1, 16]             272\n",
      "              ReLU-7                   [-1, 16]               0\n",
      "            Linear-8                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n",
      "FisherPartitioner: param: 12544 - partition: 32 - nº part: 392 - block updates: 2\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 2\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 2\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 160 - partition: 32 - nº part: 5 - block updates: 2\n",
      "FisherPartitioner: param: 10 - partition: 32 - nº part: 1 - block updates: 1\n",
      "total partitions: 417 - effective block updates: 12\n",
      "initializing buffers and inverses...\n",
      "partition 1/417\n",
      "partition 417/417\n",
      "starting epoch: 1/10\n",
      "batch: 100/1875 - train loss: 13.0415 - test loss: 12.9515 - train acc: 0.1097 - test acc: 0.1676 - 0m 0s\n",
      "batch: 200/1875 - train loss: 12.8073 - test loss: 12.4889 - train acc: 0.1841 - test acc: 0.2954 - 0m 3s\n",
      "batch: 300/1875 - train loss: 11.6233 - test loss: 10.4809 - train acc: 0.2588 - test acc: 0.2838 - 0m 6s\n",
      "batch: 400/1875 - train loss: 9.3964 - test loss: 7.9936 - train acc: 0.3888 - test acc: 0.4985 - 0m 9s\n",
      "batch: 500/1875 - train loss: 6.8679 - test loss: 5.1945 - train acc: 0.5788 - test acc: 0.6696 - 0m 11s\n",
      "batch: 600/1875 - train loss: 5.0816 - test loss: 4.4923 - train acc: 0.6813 - test acc: 0.7091 - 0m 14s\n",
      "batch: 700/1875 - train loss: 4.2459 - test loss: 3.8997 - train acc: 0.7434 - test acc: 0.7722 - 0m 16s\n",
      "batch: 800/1875 - train loss: 3.9979 - test loss: 3.3595 - train acc: 0.7728 - test acc: 0.8117 - 0m 19s\n",
      "batch: 900/1875 - train loss: 3.3142 - test loss: 3.2000 - train acc: 0.8168 - test acc: 0.8172 - 0m 21s\n",
      "batch: 1000/1875 - train loss: 3.2214 - test loss: 2.9913 - train acc: 0.8184 - test acc: 0.8296 - 0m 24s\n",
      "batch: 1100/1875 - train loss: 2.9221 - test loss: 2.7328 - train acc: 0.8471 - test acc: 0.8577 - 0m 26s\n",
      "batch: 1200/1875 - train loss: 2.7646 - test loss: 2.6348 - train acc: 0.8546 - test acc: 0.8559 - 0m 29s\n",
      "batch: 1300/1875 - train loss: 2.7201 - test loss: 2.3086 - train acc: 0.8581 - test acc: 0.8783 - 0m 32s\n",
      "batch: 1400/1875 - train loss: 2.4545 - test loss: 2.3913 - train acc: 0.8691 - test acc: 0.8728 - 0m 35s\n",
      "batch: 1500/1875 - train loss: 2.4017 - test loss: 2.0803 - train acc: 0.8778 - test acc: 0.8905 - 0m 37s\n",
      "batch: 1600/1875 - train loss: 2.1843 - test loss: 1.9609 - train acc: 0.8882 - test acc: 0.8987 - 0m 40s\n",
      "batch: 1700/1875 - train loss: 2.2671 - test loss: 1.9604 - train acc: 0.8806 - test acc: 0.8996 - 0m 43s\n",
      "batch: 1800/1875 - train loss: 2.1126 - test loss: 1.8761 - train acc: 0.8910 - test acc: 0.9000 - 0m 45s\n",
      "batch: 1875/1875 - train loss: 1.8433 - test loss: 1.9011 - train acc: 0.9054 - test acc: 0.9020 - 0m 47s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 2/10\n",
      "batch: 100/1875 - train loss: 1.9033 - test loss: 1.8313 - train acc: 0.8976 - test acc: 0.9035 - 0m 50s\n",
      "batch: 200/1875 - train loss: 1.8730 - test loss: 1.7814 - train acc: 0.9079 - test acc: 0.9043 - 0m 53s\n",
      "batch: 300/1875 - train loss: 2.0126 - test loss: 1.8731 - train acc: 0.9017 - test acc: 0.9019 - 0m 55s\n",
      "batch: 400/1875 - train loss: 1.7432 - test loss: 1.7685 - train acc: 0.9139 - test acc: 0.9090 - 0m 58s\n",
      "batch: 500/1875 - train loss: 1.8540 - test loss: 1.7070 - train acc: 0.9054 - test acc: 0.9143 - 1m 0s\n",
      "batch: 600/1875 - train loss: 1.8326 - test loss: 1.6347 - train acc: 0.9019 - test acc: 0.9144 - 1m 3s\n",
      "batch: 700/1875 - train loss: 1.7343 - test loss: 1.5427 - train acc: 0.9094 - test acc: 0.9200 - 1m 6s\n",
      "batch: 800/1875 - train loss: 1.6043 - test loss: 1.7386 - train acc: 0.9185 - test acc: 0.9107 - 1m 8s\n",
      "batch: 900/1875 - train loss: 1.6268 - test loss: 1.6385 - train acc: 0.9101 - test acc: 0.9140 - 1m 11s\n",
      "batch: 1000/1875 - train loss: 1.6811 - test loss: 1.7165 - train acc: 0.9132 - test acc: 0.9079 - 1m 14s\n",
      "batch: 1100/1875 - train loss: 1.6220 - test loss: 1.6621 - train acc: 0.9167 - test acc: 0.9135 - 1m 16s\n",
      "batch: 1200/1875 - train loss: 1.6102 - test loss: 1.4884 - train acc: 0.9198 - test acc: 0.9257 - 1m 19s\n",
      "batch: 1300/1875 - train loss: 1.4248 - test loss: 1.4108 - train acc: 0.9252 - test acc: 0.9248 - 1m 21s\n",
      "batch: 1400/1875 - train loss: 1.4717 - test loss: 1.4282 - train acc: 0.9267 - test acc: 0.9245 - 1m 24s\n",
      "batch: 1500/1875 - train loss: 1.5081 - test loss: 1.4063 - train acc: 0.9236 - test acc: 0.9258 - 1m 26s\n",
      "batch: 1600/1875 - train loss: 1.5269 - test loss: 1.3813 - train acc: 0.9239 - test acc: 0.9267 - 1m 29s\n",
      "batch: 1700/1875 - train loss: 1.4315 - test loss: 1.4247 - train acc: 0.9267 - test acc: 0.9258 - 1m 31s\n",
      "batch: 1800/1875 - train loss: 1.3912 - test loss: 1.3707 - train acc: 0.9296 - test acc: 0.9269 - 1m 34s\n",
      "batch: 1875/1875 - train loss: 1.3021 - test loss: 1.4301 - train acc: 0.9329 - test acc: 0.9250 - 1m 37s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 3/10\n",
      "batch: 100/1875 - train loss: 1.2671 - test loss: 1.3337 - train acc: 0.9336 - test acc: 0.9300 - 1m 40s\n",
      "batch: 200/1875 - train loss: 1.2865 - test loss: 1.3424 - train acc: 0.9326 - test acc: 0.9284 - 1m 43s\n",
      "batch: 300/1875 - train loss: 1.2475 - test loss: 1.3399 - train acc: 0.9392 - test acc: 0.9286 - 1m 45s\n",
      "batch: 400/1875 - train loss: 1.2776 - test loss: 1.2666 - train acc: 0.9368 - test acc: 0.9340 - 1m 48s\n",
      "batch: 500/1875 - train loss: 1.3572 - test loss: 1.3290 - train acc: 0.9323 - test acc: 0.9308 - 1m 50s\n",
      "batch: 600/1875 - train loss: 1.2984 - test loss: 1.3013 - train acc: 0.9295 - test acc: 0.9329 - 1m 53s\n",
      "batch: 700/1875 - train loss: 1.2864 - test loss: 1.3282 - train acc: 0.9324 - test acc: 0.9333 - 1m 56s\n",
      "batch: 800/1875 - train loss: 1.2949 - test loss: 1.3012 - train acc: 0.9285 - test acc: 0.9301 - 1m 58s\n",
      "batch: 900/1875 - train loss: 1.1621 - test loss: 1.4194 - train acc: 0.9392 - test acc: 0.9267 - 2m 1s\n",
      "batch: 1000/1875 - train loss: 1.2429 - test loss: 1.3392 - train acc: 0.9386 - test acc: 0.9304 - 2m 3s\n",
      "batch: 1100/1875 - train loss: 1.1661 - test loss: 1.1976 - train acc: 0.9377 - test acc: 0.9352 - 2m 6s\n",
      "batch: 1200/1875 - train loss: 1.2409 - test loss: 1.1646 - train acc: 0.9374 - test acc: 0.9386 - 2m 9s\n",
      "batch: 1300/1875 - train loss: 1.4265 - test loss: 1.4495 - train acc: 0.9270 - test acc: 0.9191 - 2m 12s\n",
      "batch: 1400/1875 - train loss: 1.4190 - test loss: 1.2258 - train acc: 0.9286 - test acc: 0.9359 - 2m 14s\n",
      "batch: 1500/1875 - train loss: 1.2849 - test loss: 1.2173 - train acc: 0.9327 - test acc: 0.9359 - 2m 17s\n",
      "batch: 1600/1875 - train loss: 1.2029 - test loss: 1.2427 - train acc: 0.9461 - test acc: 0.9362 - 2m 20s\n",
      "batch: 1700/1875 - train loss: 1.3065 - test loss: 1.2359 - train acc: 0.9301 - test acc: 0.9359 - 2m 22s\n",
      "batch: 1800/1875 - train loss: 1.2395 - test loss: 1.2768 - train acc: 0.9367 - test acc: 0.9318 - 2m 25s\n",
      "batch: 1875/1875 - train loss: 1.3317 - test loss: 1.1898 - train acc: 0.9326 - test acc: 0.9385 - 2m 27s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 4/10\n",
      "batch: 100/1875 - train loss: 1.1845 - test loss: 1.1571 - train acc: 0.9367 - test acc: 0.9390 - 2m 30s\n",
      "batch: 200/1875 - train loss: 1.1284 - test loss: 1.1965 - train acc: 0.9436 - test acc: 0.9384 - 2m 32s\n",
      "batch: 300/1875 - train loss: 0.9940 - test loss: 1.2530 - train acc: 0.9461 - test acc: 0.9346 - 2m 35s\n",
      "batch: 400/1875 - train loss: 1.2244 - test loss: 1.2542 - train acc: 0.9358 - test acc: 0.9334 - 2m 37s\n",
      "batch: 500/1875 - train loss: 1.0219 - test loss: 1.2243 - train acc: 0.9464 - test acc: 0.9357 - 2m 40s\n",
      "batch: 600/1875 - train loss: 1.1786 - test loss: 1.3454 - train acc: 0.9393 - test acc: 0.9299 - 2m 43s\n",
      "batch: 700/1875 - train loss: 1.1376 - test loss: 1.2514 - train acc: 0.9389 - test acc: 0.9356 - 2m 45s\n",
      "batch: 800/1875 - train loss: 1.1932 - test loss: 1.2628 - train acc: 0.9405 - test acc: 0.9328 - 2m 48s\n",
      "batch: 900/1875 - train loss: 1.1083 - test loss: 1.2076 - train acc: 0.9398 - test acc: 0.9368 - 2m 51s\n",
      "batch: 1000/1875 - train loss: 1.2255 - test loss: 1.3047 - train acc: 0.9358 - test acc: 0.9317 - 2m 53s\n",
      "batch: 1100/1875 - train loss: 1.3212 - test loss: 1.2294 - train acc: 0.9311 - test acc: 0.9348 - 2m 56s\n",
      "batch: 1200/1875 - train loss: 1.0616 - test loss: 1.1671 - train acc: 0.9430 - test acc: 0.9389 - 2m 58s\n",
      "batch: 1300/1875 - train loss: 1.0773 - test loss: 1.1692 - train acc: 0.9452 - test acc: 0.9412 - 3m 1s\n",
      "batch: 1400/1875 - train loss: 1.2088 - test loss: 1.1860 - train acc: 0.9414 - test acc: 0.9378 - 3m 4s\n",
      "batch: 1500/1875 - train loss: 1.0707 - test loss: 1.2891 - train acc: 0.9464 - test acc: 0.9319 - 3m 6s\n",
      "batch: 1600/1875 - train loss: 1.0879 - test loss: 1.2521 - train acc: 0.9439 - test acc: 0.9376 - 3m 8s\n",
      "batch: 1700/1875 - train loss: 1.1575 - test loss: 1.1935 - train acc: 0.9415 - test acc: 0.9367 - 3m 11s\n",
      "batch: 1800/1875 - train loss: 1.1094 - test loss: 1.1849 - train acc: 0.9433 - test acc: 0.9360 - 3m 15s\n",
      "batch: 1875/1875 - train loss: 1.0049 - test loss: 1.1380 - train acc: 0.9492 - test acc: 0.9402 - 3m 17s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 5/10\n",
      "batch: 100/1875 - train loss: 1.1568 - test loss: 1.1484 - train acc: 0.9414 - test acc: 0.9407 - 3m 19s\n",
      "batch: 200/1875 - train loss: 1.1115 - test loss: 1.1897 - train acc: 0.9455 - test acc: 0.9393 - 3m 22s\n",
      "batch: 300/1875 - train loss: 1.2395 - test loss: 1.3827 - train acc: 0.9339 - test acc: 0.9295 - 3m 25s\n",
      "batch: 400/1875 - train loss: 1.0876 - test loss: 1.1010 - train acc: 0.9489 - test acc: 0.9398 - 3m 27s\n",
      "batch: 500/1875 - train loss: 1.0626 - test loss: 1.2394 - train acc: 0.9414 - test acc: 0.9370 - 3m 30s\n",
      "batch: 600/1875 - train loss: 1.0010 - test loss: 1.1633 - train acc: 0.9465 - test acc: 0.9404 - 3m 32s\n",
      "batch: 700/1875 - train loss: 0.9979 - test loss: 1.2997 - train acc: 0.9477 - test acc: 0.9311 - 3m 35s\n",
      "batch: 800/1875 - train loss: 1.0470 - test loss: 1.1313 - train acc: 0.9446 - test acc: 0.9405 - 3m 37s\n",
      "batch: 900/1875 - train loss: 1.0554 - test loss: 1.2062 - train acc: 0.9421 - test acc: 0.9381 - 3m 40s\n",
      "batch: 1000/1875 - train loss: 1.0596 - test loss: 1.1721 - train acc: 0.9405 - test acc: 0.9396 - 3m 42s\n",
      "batch: 1100/1875 - train loss: 0.9412 - test loss: 1.0895 - train acc: 0.9464 - test acc: 0.9449 - 3m 46s\n",
      "batch: 1200/1875 - train loss: 1.1287 - test loss: 1.1775 - train acc: 0.9436 - test acc: 0.9409 - 3m 49s\n",
      "batch: 1300/1875 - train loss: 1.1086 - test loss: 1.1417 - train acc: 0.9411 - test acc: 0.9417 - 3m 51s\n",
      "batch: 1400/1875 - train loss: 1.1007 - test loss: 1.2003 - train acc: 0.9471 - test acc: 0.9397 - 3m 54s\n",
      "batch: 1500/1875 - train loss: 1.1296 - test loss: 1.2161 - train acc: 0.9405 - test acc: 0.9356 - 3m 57s\n",
      "batch: 1600/1875 - train loss: 1.0279 - test loss: 1.0973 - train acc: 0.9477 - test acc: 0.9399 - 3m 59s\n",
      "batch: 1700/1875 - train loss: 1.0359 - test loss: 1.1110 - train acc: 0.9458 - test acc: 0.9427 - 4m 2s\n",
      "batch: 1800/1875 - train loss: 0.9315 - test loss: 1.1335 - train acc: 0.9467 - test acc: 0.9411 - 4m 4s\n",
      "batch: 1875/1875 - train loss: 1.0514 - test loss: 1.1170 - train acc: 0.9458 - test acc: 0.9411 - 4m 6s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 6/10\n",
      "batch: 100/1875 - train loss: 0.9063 - test loss: 1.2198 - train acc: 0.9533 - test acc: 0.9340 - 4m 9s\n",
      "batch: 200/1875 - train loss: 1.0299 - test loss: 1.1440 - train acc: 0.9483 - test acc: 0.9398 - 4m 12s\n",
      "batch: 300/1875 - train loss: 0.9378 - test loss: 1.0941 - train acc: 0.9502 - test acc: 0.9408 - 4m 14s\n",
      "batch: 400/1875 - train loss: 0.9431 - test loss: 1.3380 - train acc: 0.9489 - test acc: 0.9339 - 4m 17s\n",
      "batch: 500/1875 - train loss: 1.0306 - test loss: 1.0985 - train acc: 0.9442 - test acc: 0.9416 - 4m 20s\n",
      "batch: 600/1875 - train loss: 0.9986 - test loss: 1.1612 - train acc: 0.9487 - test acc: 0.9400 - 4m 22s\n",
      "batch: 700/1875 - train loss: 0.9416 - test loss: 1.2060 - train acc: 0.9540 - test acc: 0.9365 - 4m 25s\n",
      "batch: 800/1875 - train loss: 0.9796 - test loss: 1.1301 - train acc: 0.9471 - test acc: 0.9411 - 4m 27s\n",
      "batch: 900/1875 - train loss: 1.0248 - test loss: 1.1370 - train acc: 0.9467 - test acc: 0.9421 - 4m 30s\n",
      "batch: 1000/1875 - train loss: 1.0434 - test loss: 1.2325 - train acc: 0.9458 - test acc: 0.9350 - 4m 33s\n",
      "batch: 1100/1875 - train loss: 1.0818 - test loss: 1.0280 - train acc: 0.9439 - test acc: 0.9455 - 4m 35s\n",
      "batch: 1200/1875 - train loss: 0.9794 - test loss: 1.0654 - train acc: 0.9449 - test acc: 0.9466 - 4m 38s\n",
      "batch: 1300/1875 - train loss: 1.0026 - test loss: 1.0365 - train acc: 0.9471 - test acc: 0.9459 - 4m 41s\n",
      "batch: 1400/1875 - train loss: 0.9559 - test loss: 1.0879 - train acc: 0.9489 - test acc: 0.9451 - 4m 43s\n",
      "batch: 1500/1875 - train loss: 1.0316 - test loss: 1.0551 - train acc: 0.9498 - test acc: 0.9462 - 4m 46s\n",
      "batch: 1600/1875 - train loss: 1.0774 - test loss: 1.2009 - train acc: 0.9411 - test acc: 0.9363 - 4m 49s\n",
      "batch: 1700/1875 - train loss: 1.0733 - test loss: 1.0522 - train acc: 0.9430 - test acc: 0.9482 - 4m 52s\n",
      "batch: 1800/1875 - train loss: 1.0135 - test loss: 1.0798 - train acc: 0.9480 - test acc: 0.9443 - 4m 54s\n",
      "batch: 1875/1875 - train loss: 0.8972 - test loss: 1.1156 - train acc: 0.9505 - test acc: 0.9435 - 4m 56s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 7/10\n",
      "batch: 100/1875 - train loss: 0.8357 - test loss: 1.0248 - train acc: 0.9543 - test acc: 0.9461 - 4m 59s\n",
      "time is up! finishing training\n",
      "batch: 101/1875 - train loss: 0.8338 - test loss: 1.0276 - train acc: 0.9540 - test acc: 0.9459 - 5m 1s\n",
      "GPU memory used: 0.00 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "testing: partition-size: 32 - buffer-size: 64 - block_updates: 8\n",
      "generating MNIST data with 10 classes\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 16]          12,560\n",
      "              ReLU-3                   [-1, 16]               0\n",
      "            Linear-4                   [-1, 16]             272\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "            Linear-6                   [-1, 16]             272\n",
      "              ReLU-7                   [-1, 16]               0\n",
      "            Linear-8                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n",
      "FisherPartitioner: param: 12544 - partition: 32 - nº part: 392 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 160 - partition: 32 - nº part: 5 - block updates: 5\n",
      "FisherPartitioner: param: 10 - partition: 32 - nº part: 1 - block updates: 1\n",
      "total partitions: 417 - effective block updates: 33\n",
      "initializing buffers and inverses...\n",
      "partition 1/417\n",
      "partition 417/417\n",
      "starting epoch: 1/10\n",
      "batch: 100/1875 - train loss: 12.9838 - test loss: 12.8021 - train acc: 0.1096 - test acc: 0.1912 - 0m 0s\n",
      "batch: 200/1875 - train loss: 12.3489 - test loss: 11.7987 - train acc: 0.2628 - test acc: 0.2470 - 0m 3s\n",
      "batch: 300/1875 - train loss: 11.1754 - test loss: 10.2879 - train acc: 0.3422 - test acc: 0.4004 - 0m 5s\n",
      "batch: 400/1875 - train loss: 9.0148 - test loss: 7.6041 - train acc: 0.4825 - test acc: 0.5644 - 0m 8s\n",
      "batch: 500/1875 - train loss: 6.5776 - test loss: 5.6057 - train acc: 0.6304 - test acc: 0.6865 - 0m 11s\n",
      "batch: 600/1875 - train loss: 4.7290 - test loss: 4.1887 - train acc: 0.7378 - test acc: 0.7776 - 0m 13s\n",
      "batch: 700/1875 - train loss: 3.8368 - test loss: 3.7509 - train acc: 0.7921 - test acc: 0.7935 - 0m 15s\n",
      "batch: 800/1875 - train loss: 3.5580 - test loss: 3.0839 - train acc: 0.8087 - test acc: 0.8345 - 0m 19s\n",
      "batch: 900/1875 - train loss: 3.2620 - test loss: 2.8470 - train acc: 0.8259 - test acc: 0.8496 - 0m 21s\n",
      "batch: 1000/1875 - train loss: 2.9959 - test loss: 2.6984 - train acc: 0.8362 - test acc: 0.8556 - 0m 24s\n",
      "batch: 1100/1875 - train loss: 2.8182 - test loss: 2.6278 - train acc: 0.8434 - test acc: 0.8609 - 0m 26s\n",
      "batch: 1200/1875 - train loss: 2.5699 - test loss: 2.5153 - train acc: 0.8650 - test acc: 0.8681 - 0m 29s\n",
      "batch: 1300/1875 - train loss: 2.5122 - test loss: 2.3819 - train acc: 0.8703 - test acc: 0.8729 - 0m 31s\n",
      "batch: 1400/1875 - train loss: 2.5725 - test loss: 2.2794 - train acc: 0.8672 - test acc: 0.8837 - 0m 34s\n",
      "batch: 1500/1875 - train loss: 2.2563 - test loss: 2.3110 - train acc: 0.8844 - test acc: 0.8795 - 0m 36s\n",
      "batch: 1600/1875 - train loss: 2.3766 - test loss: 2.2913 - train acc: 0.8773 - test acc: 0.8756 - 0m 39s\n",
      "batch: 1700/1875 - train loss: 2.3505 - test loss: 2.1268 - train acc: 0.8804 - test acc: 0.8863 - 0m 41s\n",
      "batch: 1800/1875 - train loss: 2.0275 - test loss: 2.1335 - train acc: 0.8954 - test acc: 0.8888 - 0m 44s\n",
      "batch: 1875/1875 - train loss: 2.2223 - test loss: 2.0770 - train acc: 0.8885 - test acc: 0.8931 - 0m 47s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 2/10\n",
      "batch: 100/1875 - train loss: 2.0238 - test loss: 2.0005 - train acc: 0.8938 - test acc: 0.8987 - 0m 50s\n",
      "batch: 200/1875 - train loss: 1.9066 - test loss: 1.9690 - train acc: 0.8953 - test acc: 0.8967 - 0m 52s\n",
      "batch: 300/1875 - train loss: 1.9551 - test loss: 1.9419 - train acc: 0.8988 - test acc: 0.8972 - 0m 55s\n",
      "batch: 400/1875 - train loss: 2.0516 - test loss: 1.8999 - train acc: 0.8935 - test acc: 0.9004 - 0m 57s\n",
      "batch: 500/1875 - train loss: 1.8835 - test loss: 1.8666 - train acc: 0.8985 - test acc: 0.9033 - 1m 0s\n",
      "batch: 600/1875 - train loss: 1.9667 - test loss: 1.8187 - train acc: 0.8963 - test acc: 0.9054 - 1m 2s\n",
      "batch: 700/1875 - train loss: 2.0210 - test loss: 1.7942 - train acc: 0.8973 - test acc: 0.9081 - 1m 5s\n",
      "batch: 800/1875 - train loss: 1.9918 - test loss: 1.7569 - train acc: 0.9026 - test acc: 0.9095 - 1m 8s\n",
      "batch: 900/1875 - train loss: 1.7418 - test loss: 1.6895 - train acc: 0.9085 - test acc: 0.9145 - 1m 10s\n",
      "batch: 1000/1875 - train loss: 1.7986 - test loss: 1.7159 - train acc: 0.9047 - test acc: 0.9102 - 1m 13s\n",
      "batch: 1100/1875 - train loss: 1.6901 - test loss: 1.5982 - train acc: 0.9114 - test acc: 0.9188 - 1m 15s\n",
      "batch: 1200/1875 - train loss: 1.8961 - test loss: 1.6243 - train acc: 0.9051 - test acc: 0.9144 - 1m 18s\n",
      "batch: 1300/1875 - train loss: 1.7246 - test loss: 1.5452 - train acc: 0.9108 - test acc: 0.9196 - 1m 21s\n",
      "batch: 1400/1875 - train loss: 1.6349 - test loss: 1.5582 - train acc: 0.9198 - test acc: 0.9196 - 1m 24s\n",
      "batch: 1500/1875 - train loss: 1.7874 - test loss: 1.7086 - train acc: 0.9079 - test acc: 0.9102 - 1m 26s\n",
      "batch: 1600/1875 - train loss: 1.6017 - test loss: 1.4913 - train acc: 0.9129 - test acc: 0.9237 - 1m 29s\n",
      "batch: 1700/1875 - train loss: 1.6970 - test loss: 1.5386 - train acc: 0.9132 - test acc: 0.9190 - 1m 32s\n",
      "batch: 1800/1875 - train loss: 1.4690 - test loss: 1.4915 - train acc: 0.9255 - test acc: 0.9243 - 1m 34s\n",
      "batch: 1875/1875 - train loss: 1.5612 - test loss: 1.4901 - train acc: 0.9198 - test acc: 0.9228 - 1m 36s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 3/10\n",
      "batch: 100/1875 - train loss: 1.5231 - test loss: 1.5932 - train acc: 0.9195 - test acc: 0.9191 - 1m 39s\n",
      "batch: 200/1875 - train loss: 1.5028 - test loss: 1.4309 - train acc: 0.9223 - test acc: 0.9262 - 1m 42s\n",
      "batch: 300/1875 - train loss: 1.5375 - test loss: 1.4193 - train acc: 0.9232 - test acc: 0.9253 - 1m 44s\n",
      "batch: 400/1875 - train loss: 1.4656 - test loss: 1.4629 - train acc: 0.9267 - test acc: 0.9267 - 1m 47s\n",
      "batch: 500/1875 - train loss: 1.6671 - test loss: 1.4081 - train acc: 0.9133 - test acc: 0.9295 - 1m 49s\n",
      "batch: 600/1875 - train loss: 1.6519 - test loss: 1.3788 - train acc: 0.9157 - test acc: 0.9279 - 1m 52s\n",
      "batch: 700/1875 - train loss: 1.4091 - test loss: 1.4178 - train acc: 0.9283 - test acc: 0.9263 - 1m 55s\n",
      "batch: 800/1875 - train loss: 1.3962 - test loss: 1.3778 - train acc: 0.9305 - test acc: 0.9288 - 1m 58s\n",
      "batch: 900/1875 - train loss: 1.1960 - test loss: 1.3701 - train acc: 0.9389 - test acc: 0.9290 - 2m 0s\n",
      "batch: 1000/1875 - train loss: 1.5159 - test loss: 1.3230 - train acc: 0.9195 - test acc: 0.9337 - 2m 3s\n",
      "batch: 1100/1875 - train loss: 1.3917 - test loss: 1.3944 - train acc: 0.9311 - test acc: 0.9280 - 2m 5s\n",
      "batch: 1200/1875 - train loss: 1.3802 - test loss: 1.3739 - train acc: 0.9273 - test acc: 0.9302 - 2m 8s\n",
      "batch: 1300/1875 - train loss: 1.2629 - test loss: 1.2692 - train acc: 0.9320 - test acc: 0.9362 - 2m 10s\n",
      "batch: 1400/1875 - train loss: 1.2345 - test loss: 1.2844 - train acc: 0.9361 - test acc: 0.9343 - 2m 13s\n",
      "batch: 1500/1875 - train loss: 1.2887 - test loss: 1.3607 - train acc: 0.9351 - test acc: 0.9308 - 2m 15s\n",
      "batch: 1600/1875 - train loss: 1.4748 - test loss: 1.4327 - train acc: 0.9223 - test acc: 0.9240 - 2m 18s\n",
      "batch: 1700/1875 - train loss: 1.3991 - test loss: 1.2994 - train acc: 0.9346 - test acc: 0.9319 - 2m 21s\n",
      "batch: 1800/1875 - train loss: 1.2807 - test loss: 1.3066 - train acc: 0.9333 - test acc: 0.9315 - 2m 23s\n",
      "batch: 1875/1875 - train loss: 1.5110 - test loss: 1.2287 - train acc: 0.9239 - test acc: 0.9371 - 2m 26s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 4/10\n",
      "batch: 100/1875 - train loss: 1.2370 - test loss: 1.2410 - train acc: 0.9311 - test acc: 0.9353 - 2m 29s\n",
      "batch: 200/1875 - train loss: 1.2953 - test loss: 1.2667 - train acc: 0.9327 - test acc: 0.9326 - 2m 31s\n",
      "batch: 300/1875 - train loss: 1.2370 - test loss: 1.1856 - train acc: 0.9364 - test acc: 0.9383 - 2m 34s\n",
      "batch: 400/1875 - train loss: 1.1670 - test loss: 1.2262 - train acc: 0.9401 - test acc: 0.9383 - 2m 36s\n",
      "batch: 500/1875 - train loss: 1.1847 - test loss: 1.2054 - train acc: 0.9370 - test acc: 0.9377 - 2m 39s\n",
      "batch: 600/1875 - train loss: 1.3235 - test loss: 1.1722 - train acc: 0.9355 - test acc: 0.9392 - 2m 41s\n",
      "batch: 700/1875 - train loss: 1.2666 - test loss: 1.2372 - train acc: 0.9355 - test acc: 0.9359 - 2m 44s\n",
      "batch: 800/1875 - train loss: 1.1848 - test loss: 1.2702 - train acc: 0.9348 - test acc: 0.9332 - 2m 47s\n",
      "batch: 900/1875 - train loss: 1.2360 - test loss: 1.2491 - train acc: 0.9364 - test acc: 0.9348 - 2m 49s\n",
      "batch: 1000/1875 - train loss: 1.1912 - test loss: 1.1712 - train acc: 0.9414 - test acc: 0.9387 - 2m 52s\n",
      "batch: 1100/1875 - train loss: 1.2305 - test loss: 1.1618 - train acc: 0.9324 - test acc: 0.9399 - 2m 54s\n",
      "batch: 1200/1875 - train loss: 1.2293 - test loss: 1.1435 - train acc: 0.9389 - test acc: 0.9410 - 2m 57s\n",
      "batch: 1300/1875 - train loss: 1.2523 - test loss: 1.1355 - train acc: 0.9336 - test acc: 0.9426 - 3m 0s\n",
      "batch: 1400/1875 - train loss: 1.0459 - test loss: 1.3491 - train acc: 0.9467 - test acc: 0.9301 - 3m 2s\n",
      "batch: 1500/1875 - train loss: 1.2305 - test loss: 1.2049 - train acc: 0.9342 - test acc: 0.9353 - 3m 5s\n",
      "batch: 1600/1875 - train loss: 1.1984 - test loss: 1.1392 - train acc: 0.9367 - test acc: 0.9415 - 3m 8s\n",
      "batch: 1700/1875 - train loss: 1.1220 - test loss: 1.2034 - train acc: 0.9427 - test acc: 0.9358 - 3m 10s\n",
      "batch: 1800/1875 - train loss: 1.1575 - test loss: 1.1297 - train acc: 0.9408 - test acc: 0.9431 - 3m 13s\n",
      "batch: 1875/1875 - train loss: 1.2279 - test loss: 1.1782 - train acc: 0.9348 - test acc: 0.9388 - 3m 15s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 5/10\n",
      "batch: 100/1875 - train loss: 1.0194 - test loss: 1.1459 - train acc: 0.9486 - test acc: 0.9407 - 3m 18s\n",
      "batch: 200/1875 - train loss: 1.0864 - test loss: 1.1368 - train acc: 0.9455 - test acc: 0.9394 - 3m 20s\n",
      "batch: 300/1875 - train loss: 1.1623 - test loss: 1.2350 - train acc: 0.9392 - test acc: 0.9349 - 3m 23s\n",
      "batch: 400/1875 - train loss: 1.0291 - test loss: 1.1400 - train acc: 0.9483 - test acc: 0.9411 - 3m 25s\n",
      "batch: 500/1875 - train loss: 1.0537 - test loss: 1.0939 - train acc: 0.9511 - test acc: 0.9443 - 3m 29s\n",
      "batch: 600/1875 - train loss: 1.1608 - test loss: 1.1596 - train acc: 0.9405 - test acc: 0.9390 - 3m 31s\n",
      "batch: 700/1875 - train loss: 1.0680 - test loss: 1.1479 - train acc: 0.9411 - test acc: 0.9402 - 3m 34s\n",
      "batch: 800/1875 - train loss: 1.0845 - test loss: 1.0755 - train acc: 0.9448 - test acc: 0.9429 - 3m 36s\n",
      "batch: 900/1875 - train loss: 1.0199 - test loss: 1.0928 - train acc: 0.9449 - test acc: 0.9448 - 3m 39s\n",
      "batch: 1000/1875 - train loss: 1.1649 - test loss: 1.0857 - train acc: 0.9424 - test acc: 0.9437 - 3m 42s\n",
      "batch: 1100/1875 - train loss: 1.0418 - test loss: 1.0756 - train acc: 0.9442 - test acc: 0.9452 - 3m 44s\n",
      "batch: 1200/1875 - train loss: 1.1341 - test loss: 1.0504 - train acc: 0.9386 - test acc: 0.9462 - 3m 47s\n",
      "batch: 1300/1875 - train loss: 1.1297 - test loss: 1.0627 - train acc: 0.9402 - test acc: 0.9433 - 3m 49s\n",
      "batch: 1400/1875 - train loss: 0.9326 - test loss: 1.0626 - train acc: 0.9508 - test acc: 0.9447 - 3m 52s\n",
      "batch: 1500/1875 - train loss: 1.0306 - test loss: 1.1130 - train acc: 0.9414 - test acc: 0.9419 - 3m 55s\n",
      "batch: 1600/1875 - train loss: 1.1892 - test loss: 1.0466 - train acc: 0.9389 - test acc: 0.9453 - 3m 57s\n",
      "batch: 1700/1875 - train loss: 1.0829 - test loss: 1.0853 - train acc: 0.9417 - test acc: 0.9435 - 4m 0s\n",
      "batch: 1800/1875 - train loss: 0.9847 - test loss: 1.0405 - train acc: 0.9464 - test acc: 0.9451 - 4m 3s\n",
      "batch: 1875/1875 - train loss: 1.0286 - test loss: 1.0462 - train acc: 0.9446 - test acc: 0.9448 - 4m 6s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 6/10\n",
      "batch: 100/1875 - train loss: 0.8803 - test loss: 1.0660 - train acc: 0.9543 - test acc: 0.9443 - 4m 8s\n",
      "batch: 200/1875 - train loss: 0.9813 - test loss: 1.1200 - train acc: 0.9461 - test acc: 0.9425 - 4m 11s\n",
      "batch: 300/1875 - train loss: 0.9089 - test loss: 1.0795 - train acc: 0.9502 - test acc: 0.9431 - 4m 13s\n",
      "batch: 400/1875 - train loss: 0.9969 - test loss: 1.1559 - train acc: 0.9471 - test acc: 0.9375 - 4m 16s\n",
      "batch: 500/1875 - train loss: 1.0093 - test loss: 1.0070 - train acc: 0.9483 - test acc: 0.9490 - 4m 19s\n",
      "batch: 600/1875 - train loss: 0.9944 - test loss: 1.0486 - train acc: 0.9474 - test acc: 0.9456 - 4m 21s\n",
      "batch: 700/1875 - train loss: 0.9325 - test loss: 1.0491 - train acc: 0.9499 - test acc: 0.9431 - 4m 24s\n",
      "batch: 800/1875 - train loss: 1.0771 - test loss: 0.9915 - train acc: 0.9455 - test acc: 0.9480 - 4m 26s\n",
      "batch: 900/1875 - train loss: 1.0162 - test loss: 0.9957 - train acc: 0.9465 - test acc: 0.9474 - 4m 29s\n",
      "batch: 1000/1875 - train loss: 0.9697 - test loss: 0.9889 - train acc: 0.9505 - test acc: 0.9487 - 4m 31s\n",
      "batch: 1100/1875 - train loss: 1.0450 - test loss: 1.0010 - train acc: 0.9471 - test acc: 0.9475 - 4m 35s\n",
      "batch: 1200/1875 - train loss: 0.9746 - test loss: 1.0354 - train acc: 0.9505 - test acc: 0.9470 - 4m 37s\n",
      "batch: 1300/1875 - train loss: 0.9014 - test loss: 1.0686 - train acc: 0.9470 - test acc: 0.9458 - 4m 40s\n",
      "batch: 1400/1875 - train loss: 1.0451 - test loss: 0.9904 - train acc: 0.9476 - test acc: 0.9501 - 4m 42s\n",
      "batch: 1500/1875 - train loss: 1.0699 - test loss: 1.0554 - train acc: 0.9427 - test acc: 0.9457 - 4m 45s\n",
      "batch: 1600/1875 - train loss: 0.8850 - test loss: 1.0757 - train acc: 0.9514 - test acc: 0.9435 - 4m 47s\n",
      "batch: 1700/1875 - train loss: 0.9699 - test loss: 1.0406 - train acc: 0.9473 - test acc: 0.9463 - 4m 50s\n",
      "batch: 1800/1875 - train loss: 0.9908 - test loss: 1.0266 - train acc: 0.9511 - test acc: 0.9452 - 4m 52s\n",
      "batch: 1875/1875 - train loss: 1.0192 - test loss: 1.0092 - train acc: 0.9405 - test acc: 0.9477 - 4m 55s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 7/10\n",
      "batch: 100/1875 - train loss: 0.8758 - test loss: 1.0424 - train acc: 0.9527 - test acc: 0.9457 - 4m 57s\n",
      "batch: 200/1875 - train loss: 0.8960 - test loss: 0.9891 - train acc: 0.9555 - test acc: 0.9484 - 5m 0s\n",
      "time is up! finishing training\n",
      "batch: 201/1875 - train loss: 0.8989 - test loss: 0.9896 - train acc: 0.9551 - test acc: 0.9480 - 5m 2s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "testing: partition-size: 32 - buffer-size: 64 - block_updates: 32\n",
      "generating MNIST data with 10 classes\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 16]          12,560\n",
      "              ReLU-3                   [-1, 16]               0\n",
      "            Linear-4                   [-1, 16]             272\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "            Linear-6                   [-1, 16]             272\n",
      "              ReLU-7                   [-1, 16]               0\n",
      "            Linear-8                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n",
      "FisherPartitioner: param: 12544 - partition: 32 - nº part: 392 - block updates: 32\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 160 - partition: 32 - nº part: 5 - block updates: 5\n",
      "FisherPartitioner: param: 10 - partition: 32 - nº part: 1 - block updates: 1\n",
      "total partitions: 417 - effective block updates: 57\n",
      "initializing buffers and inverses...\n",
      "partition 1/417\n",
      "partition 417/417\n",
      "starting epoch: 1/10\n",
      "batch: 100/1875 - train loss: 13.0178 - test loss: 12.9482 - train acc: 0.1099 - test acc: 0.2099 - 0m 0s\n",
      "batch: 200/1875 - train loss: 12.8425 - test loss: 12.6988 - train acc: 0.2444 - test acc: 0.3124 - 0m 3s\n",
      "batch: 300/1875 - train loss: 12.3421 - test loss: 11.6308 - train acc: 0.3725 - test acc: 0.3346 - 0m 6s\n",
      "batch: 400/1875 - train loss: 10.1986 - test loss: 8.7249 - train acc: 0.3710 - test acc: 0.5323 - 0m 8s\n",
      "batch: 500/1875 - train loss: 7.5892 - test loss: 6.1945 - train acc: 0.5754 - test acc: 0.6615 - 0m 11s\n",
      "batch: 600/1875 - train loss: 5.5404 - test loss: 4.8999 - train acc: 0.6734 - test acc: 0.7089 - 0m 14s\n",
      "batch: 700/1875 - train loss: 4.5677 - test loss: 4.2925 - train acc: 0.7125 - test acc: 0.7621 - 0m 16s\n",
      "batch: 800/1875 - train loss: 4.0690 - test loss: 3.7351 - train acc: 0.7696 - test acc: 0.8031 - 0m 18s\n",
      "batch: 900/1875 - train loss: 3.8152 - test loss: 3.3846 - train acc: 0.7968 - test acc: 0.8238 - 0m 21s\n",
      "batch: 1000/1875 - train loss: 3.4619 - test loss: 3.1535 - train acc: 0.8184 - test acc: 0.8368 - 0m 24s\n",
      "batch: 1100/1875 - train loss: 2.8566 - test loss: 3.0222 - train acc: 0.8509 - test acc: 0.8459 - 0m 26s\n",
      "batch: 1200/1875 - train loss: 3.1296 - test loss: 2.8755 - train acc: 0.8415 - test acc: 0.8564 - 0m 29s\n",
      "batch: 1300/1875 - train loss: 2.5892 - test loss: 2.5106 - train acc: 0.8751 - test acc: 0.8749 - 0m 32s\n",
      "batch: 1400/1875 - train loss: 2.6042 - test loss: 2.4144 - train acc: 0.8709 - test acc: 0.8772 - 0m 34s\n",
      "batch: 1500/1875 - train loss: 2.5791 - test loss: 2.2609 - train acc: 0.8687 - test acc: 0.8835 - 0m 37s\n",
      "batch: 1600/1875 - train loss: 2.3519 - test loss: 2.1752 - train acc: 0.8781 - test acc: 0.8892 - 0m 39s\n",
      "batch: 1700/1875 - train loss: 2.1811 - test loss: 2.2297 - train acc: 0.8938 - test acc: 0.8831 - 0m 42s\n",
      "batch: 1800/1875 - train loss: 2.2386 - test loss: 2.0271 - train acc: 0.8822 - test acc: 0.8948 - 0m 44s\n",
      "batch: 1875/1875 - train loss: 1.9859 - test loss: 1.9517 - train acc: 0.8970 - test acc: 0.9011 - 0m 47s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 2/10\n",
      "batch: 100/1875 - train loss: 1.9798 - test loss: 1.9096 - train acc: 0.8995 - test acc: 0.9005 - 0m 50s\n",
      "batch: 200/1875 - train loss: 1.9626 - test loss: 2.0198 - train acc: 0.9047 - test acc: 0.8937 - 0m 52s\n",
      "batch: 300/1875 - train loss: 1.8446 - test loss: 1.8208 - train acc: 0.9070 - test acc: 0.9028 - 0m 55s\n",
      "batch: 400/1875 - train loss: 2.0465 - test loss: 1.8279 - train acc: 0.8919 - test acc: 0.9030 - 0m 57s\n",
      "batch: 500/1875 - train loss: 1.9044 - test loss: 1.8261 - train acc: 0.8978 - test acc: 0.9003 - 1m 0s\n",
      "batch: 600/1875 - train loss: 1.6153 - test loss: 1.8118 - train acc: 0.9161 - test acc: 0.9054 - 1m 3s\n",
      "batch: 700/1875 - train loss: 1.8860 - test loss: 1.9794 - train acc: 0.9023 - test acc: 0.8941 - 1m 5s\n",
      "batch: 800/1875 - train loss: 1.7393 - test loss: 1.7022 - train acc: 0.9063 - test acc: 0.9086 - 1m 8s\n",
      "batch: 900/1875 - train loss: 1.6636 - test loss: 1.7050 - train acc: 0.9079 - test acc: 0.9054 - 1m 11s\n",
      "batch: 1000/1875 - train loss: 1.7584 - test loss: 1.6536 - train acc: 0.9079 - test acc: 0.9137 - 1m 13s\n",
      "batch: 1100/1875 - train loss: 1.5974 - test loss: 1.6144 - train acc: 0.9189 - test acc: 0.9125 - 1m 16s\n",
      "batch: 1200/1875 - train loss: 1.7216 - test loss: 1.5978 - train acc: 0.9151 - test acc: 0.9137 - 1m 18s\n",
      "batch: 1300/1875 - train loss: 1.6003 - test loss: 1.5958 - train acc: 0.9151 - test acc: 0.9158 - 1m 21s\n",
      "batch: 1400/1875 - train loss: 1.5119 - test loss: 1.5604 - train acc: 0.9238 - test acc: 0.9138 - 1m 24s\n",
      "batch: 1500/1875 - train loss: 1.5673 - test loss: 1.5820 - train acc: 0.9170 - test acc: 0.9149 - 1m 26s\n",
      "batch: 1600/1875 - train loss: 1.5163 - test loss: 1.4972 - train acc: 0.9179 - test acc: 0.9208 - 1m 29s\n",
      "batch: 1700/1875 - train loss: 1.4888 - test loss: 1.4507 - train acc: 0.9157 - test acc: 0.9226 - 1m 32s\n",
      "batch: 1800/1875 - train loss: 1.5139 - test loss: 1.7082 - train acc: 0.9198 - test acc: 0.9048 - 1m 34s\n",
      "batch: 1875/1875 - train loss: 1.5196 - test loss: 1.4693 - train acc: 0.9204 - test acc: 0.9218 - 1m 37s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 3/10\n",
      "batch: 100/1875 - train loss: 1.5332 - test loss: 1.4231 - train acc: 0.9192 - test acc: 0.9227 - 1m 39s\n",
      "batch: 200/1875 - train loss: 1.3462 - test loss: 1.4702 - train acc: 0.9276 - test acc: 0.9212 - 1m 42s\n",
      "batch: 300/1875 - train loss: 1.6226 - test loss: 1.4647 - train acc: 0.9167 - test acc: 0.9190 - 1m 45s\n",
      "batch: 400/1875 - train loss: 1.2871 - test loss: 1.5125 - train acc: 0.9342 - test acc: 0.9207 - 1m 47s\n",
      "batch: 500/1875 - train loss: 1.4192 - test loss: 1.5357 - train acc: 0.9227 - test acc: 0.9152 - 1m 50s\n",
      "batch: 600/1875 - train loss: 1.4523 - test loss: 1.3936 - train acc: 0.9233 - test acc: 0.9248 - 1m 53s\n",
      "batch: 700/1875 - train loss: 1.2717 - test loss: 1.3259 - train acc: 0.9292 - test acc: 0.9282 - 1m 55s\n",
      "batch: 800/1875 - train loss: 1.3563 - test loss: 1.3665 - train acc: 0.9348 - test acc: 0.9249 - 1m 58s\n",
      "batch: 900/1875 - train loss: 1.4438 - test loss: 1.3733 - train acc: 0.9274 - test acc: 0.9235 - 2m 0s\n",
      "batch: 1000/1875 - train loss: 1.3303 - test loss: 1.3406 - train acc: 0.9301 - test acc: 0.9238 - 2m 3s\n",
      "batch: 1100/1875 - train loss: 1.2988 - test loss: 1.2570 - train acc: 0.9267 - test acc: 0.9296 - 2m 6s\n",
      "batch: 1200/1875 - train loss: 1.3490 - test loss: 1.4140 - train acc: 0.9330 - test acc: 0.9216 - 2m 9s\n",
      "batch: 1300/1875 - train loss: 1.3496 - test loss: 1.3275 - train acc: 0.9317 - test acc: 0.9261 - 2m 11s\n",
      "batch: 1400/1875 - train loss: 1.2116 - test loss: 1.2867 - train acc: 0.9349 - test acc: 0.9329 - 2m 14s\n",
      "batch: 1500/1875 - train loss: 1.4657 - test loss: 1.2900 - train acc: 0.9220 - test acc: 0.9314 - 2m 16s\n",
      "batch: 1600/1875 - train loss: 1.3672 - test loss: 1.2586 - train acc: 0.9317 - test acc: 0.9333 - 2m 19s\n",
      "batch: 1700/1875 - train loss: 1.2304 - test loss: 1.2096 - train acc: 0.9380 - test acc: 0.9324 - 2m 21s\n",
      "batch: 1800/1875 - train loss: 1.3910 - test loss: 1.2551 - train acc: 0.9296 - test acc: 0.9314 - 2m 24s\n",
      "batch: 1875/1875 - train loss: 1.2733 - test loss: 1.1824 - train acc: 0.9364 - test acc: 0.9372 - 2m 27s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 4/10\n",
      "batch: 100/1875 - train loss: 1.1438 - test loss: 1.2774 - train acc: 0.9418 - test acc: 0.9317 - 2m 29s\n",
      "batch: 200/1875 - train loss: 1.2934 - test loss: 1.2007 - train acc: 0.9389 - test acc: 0.9352 - 2m 31s\n",
      "batch: 300/1875 - train loss: 1.3117 - test loss: 1.2783 - train acc: 0.9295 - test acc: 0.9295 - 2m 34s\n",
      "batch: 400/1875 - train loss: 1.1903 - test loss: 1.3044 - train acc: 0.9380 - test acc: 0.9291 - 2m 37s\n",
      "batch: 500/1875 - train loss: 1.2026 - test loss: 1.1814 - train acc: 0.9395 - test acc: 0.9361 - 2m 40s\n",
      "batch: 600/1875 - train loss: 1.2946 - test loss: 1.2188 - train acc: 0.9311 - test acc: 0.9360 - 2m 42s\n",
      "batch: 700/1875 - train loss: 1.1301 - test loss: 1.2574 - train acc: 0.9436 - test acc: 0.9299 - 2m 45s\n",
      "batch: 800/1875 - train loss: 1.2200 - test loss: 1.2741 - train acc: 0.9339 - test acc: 0.9302 - 2m 48s\n",
      "batch: 900/1875 - train loss: 1.0911 - test loss: 1.1828 - train acc: 0.9502 - test acc: 0.9355 - 2m 50s\n",
      "batch: 1000/1875 - train loss: 1.1830 - test loss: 1.1582 - train acc: 0.9389 - test acc: 0.9374 - 2m 52s\n",
      "batch: 1100/1875 - train loss: 1.1220 - test loss: 1.3208 - train acc: 0.9383 - test acc: 0.9294 - 2m 55s\n",
      "batch: 1200/1875 - train loss: 1.3163 - test loss: 1.2549 - train acc: 0.9346 - test acc: 0.9337 - 2m 58s\n",
      "batch: 1300/1875 - train loss: 1.1873 - test loss: 1.1738 - train acc: 0.9396 - test acc: 0.9374 - 3m 0s\n",
      "batch: 1400/1875 - train loss: 1.2091 - test loss: 1.2062 - train acc: 0.9330 - test acc: 0.9334 - 3m 3s\n",
      "batch: 1500/1875 - train loss: 1.0108 - test loss: 1.2261 - train acc: 0.9449 - test acc: 0.9301 - 3m 5s\n",
      "batch: 1600/1875 - train loss: 1.2342 - test loss: 1.1969 - train acc: 0.9361 - test acc: 0.9345 - 3m 8s\n",
      "batch: 1700/1875 - train loss: 1.1548 - test loss: 1.1848 - train acc: 0.9405 - test acc: 0.9380 - 3m 11s\n",
      "batch: 1800/1875 - train loss: 1.1064 - test loss: 1.1149 - train acc: 0.9424 - test acc: 0.9398 - 3m 14s\n",
      "batch: 1875/1875 - train loss: 1.0943 - test loss: 1.1389 - train acc: 0.9458 - test acc: 0.9382 - 3m 16s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 5/10\n",
      "batch: 100/1875 - train loss: 1.0757 - test loss: 1.2016 - train acc: 0.9430 - test acc: 0.9361 - 3m 19s\n",
      "batch: 200/1875 - train loss: 0.9667 - test loss: 1.1156 - train acc: 0.9480 - test acc: 0.9402 - 3m 22s\n",
      "batch: 300/1875 - train loss: 1.0814 - test loss: 1.1142 - train acc: 0.9455 - test acc: 0.9384 - 3m 24s\n",
      "batch: 400/1875 - train loss: 1.1403 - test loss: 1.1695 - train acc: 0.9392 - test acc: 0.9351 - 3m 27s\n",
      "batch: 500/1875 - train loss: 1.0655 - test loss: 1.1046 - train acc: 0.9427 - test acc: 0.9424 - 3m 29s\n",
      "batch: 600/1875 - train loss: 1.1796 - test loss: 1.1849 - train acc: 0.9404 - test acc: 0.9379 - 3m 32s\n",
      "batch: 700/1875 - train loss: 1.1808 - test loss: 1.0964 - train acc: 0.9358 - test acc: 0.9421 - 3m 35s\n",
      "batch: 800/1875 - train loss: 1.1072 - test loss: 1.1709 - train acc: 0.9427 - test acc: 0.9396 - 3m 37s\n",
      "batch: 900/1875 - train loss: 1.1354 - test loss: 1.0987 - train acc: 0.9352 - test acc: 0.9405 - 3m 40s\n",
      "batch: 1000/1875 - train loss: 1.0473 - test loss: 1.0852 - train acc: 0.9449 - test acc: 0.9422 - 3m 43s\n",
      "batch: 1100/1875 - train loss: 1.0416 - test loss: 1.0562 - train acc: 0.9473 - test acc: 0.9429 - 3m 46s\n",
      "batch: 1200/1875 - train loss: 0.9041 - test loss: 1.0686 - train acc: 0.9527 - test acc: 0.9438 - 3m 48s\n",
      "batch: 1300/1875 - train loss: 1.1036 - test loss: 1.0893 - train acc: 0.9421 - test acc: 0.9397 - 3m 51s\n",
      "batch: 1400/1875 - train loss: 0.9882 - test loss: 1.0437 - train acc: 0.9530 - test acc: 0.9448 - 3m 54s\n",
      "batch: 1500/1875 - train loss: 0.9893 - test loss: 1.0048 - train acc: 0.9489 - test acc: 0.9476 - 3m 56s\n",
      "batch: 1600/1875 - train loss: 0.9764 - test loss: 1.0486 - train acc: 0.9480 - test acc: 0.9446 - 3m 59s\n",
      "batch: 1700/1875 - train loss: 1.0404 - test loss: 1.0517 - train acc: 0.9386 - test acc: 0.9429 - 4m 1s\n",
      "batch: 1800/1875 - train loss: 1.0974 - test loss: 1.0305 - train acc: 0.9451 - test acc: 0.9433 - 4m 4s\n",
      "batch: 1875/1875 - train loss: 1.0634 - test loss: 1.0532 - train acc: 0.9445 - test acc: 0.9449 - 4m 6s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 6/10\n",
      "batch: 100/1875 - train loss: 0.8768 - test loss: 1.0649 - train acc: 0.9536 - test acc: 0.9437 - 4m 9s\n",
      "batch: 200/1875 - train loss: 0.8193 - test loss: 1.0947 - train acc: 0.9555 - test acc: 0.9436 - 4m 11s\n",
      "batch: 300/1875 - train loss: 0.9599 - test loss: 1.0297 - train acc: 0.9471 - test acc: 0.9458 - 4m 14s\n",
      "batch: 400/1875 - train loss: 0.9361 - test loss: 1.0508 - train acc: 0.9499 - test acc: 0.9445 - 4m 17s\n",
      "batch: 500/1875 - train loss: 1.0189 - test loss: 1.0747 - train acc: 0.9499 - test acc: 0.9418 - 4m 20s\n",
      "batch: 600/1875 - train loss: 0.9867 - test loss: 1.0650 - train acc: 0.9499 - test acc: 0.9439 - 4m 22s\n",
      "batch: 700/1875 - train loss: 0.9144 - test loss: 1.0655 - train acc: 0.9520 - test acc: 0.9446 - 4m 25s\n",
      "batch: 800/1875 - train loss: 1.0252 - test loss: 1.0254 - train acc: 0.9508 - test acc: 0.9465 - 4m 28s\n",
      "batch: 900/1875 - train loss: 0.9360 - test loss: 1.1034 - train acc: 0.9486 - test acc: 0.9426 - 4m 30s\n",
      "batch: 1000/1875 - train loss: 0.9803 - test loss: 1.0767 - train acc: 0.9433 - test acc: 0.9424 - 4m 33s\n",
      "batch: 1100/1875 - train loss: 1.0757 - test loss: 0.9907 - train acc: 0.9461 - test acc: 0.9492 - 4m 35s\n",
      "batch: 1200/1875 - train loss: 1.0039 - test loss: 0.9910 - train acc: 0.9502 - test acc: 0.9472 - 4m 38s\n",
      "batch: 1300/1875 - train loss: 1.0347 - test loss: 1.0871 - train acc: 0.9495 - test acc: 0.9423 - 4m 41s\n",
      "batch: 1400/1875 - train loss: 0.9078 - test loss: 0.9928 - train acc: 0.9521 - test acc: 0.9456 - 4m 43s\n",
      "batch: 1500/1875 - train loss: 1.1273 - test loss: 1.0713 - train acc: 0.9414 - test acc: 0.9432 - 4m 46s\n",
      "batch: 1600/1875 - train loss: 0.9315 - test loss: 1.0225 - train acc: 0.9493 - test acc: 0.9481 - 4m 49s\n",
      "batch: 1700/1875 - train loss: 1.0044 - test loss: 0.9754 - train acc: 0.9405 - test acc: 0.9487 - 4m 51s\n",
      "batch: 1800/1875 - train loss: 0.9099 - test loss: 1.0168 - train acc: 0.9555 - test acc: 0.9484 - 4m 54s\n",
      "batch: 1875/1875 - train loss: 1.1240 - test loss: 1.1040 - train acc: 0.9415 - test acc: 0.9396 - 4m 56s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 7/10\n",
      "batch: 100/1875 - train loss: 0.8634 - test loss: 1.0344 - train acc: 0.9599 - test acc: 0.9449 - 4m 59s\n",
      "time is up! finishing training\n",
      "batch: 101/1875 - train loss: 0.8722 - test loss: 1.0308 - train acc: 0.9589 - test acc: 0.9458 - 5m 1s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "testing: partition-size: 32 - buffer-size: 64 - block_updates: 128\n",
      "generating MNIST data with 10 classes\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 16]          12,560\n",
      "              ReLU-3                   [-1, 16]               0\n",
      "            Linear-4                   [-1, 16]             272\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "            Linear-6                   [-1, 16]             272\n",
      "              ReLU-7                   [-1, 16]               0\n",
      "            Linear-8                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n",
      "FisherPartitioner: param: 12544 - partition: 32 - nº part: 392 - block updates: 128\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 160 - partition: 32 - nº part: 5 - block updates: 5\n",
      "FisherPartitioner: param: 10 - partition: 32 - nº part: 1 - block updates: 1\n",
      "total partitions: 417 - effective block updates: 153\n",
      "initializing buffers and inverses...\n",
      "partition 1/417\n",
      "partition 417/417\n",
      "starting epoch: 1/10\n",
      "batch: 100/1875 - train loss: 13.0295 - test loss: 12.9250 - train acc: 0.1172 - test acc: 0.1708 - 0m 0s\n",
      "batch: 200/1875 - train loss: 12.8082 - test loss: 12.6219 - train acc: 0.2138 - test acc: 0.2686 - 0m 3s\n",
      "batch: 300/1875 - train loss: 12.1507 - test loss: 11.4513 - train acc: 0.2731 - test acc: 0.3233 - 0m 5s\n",
      "batch: 400/1875 - train loss: 10.4936 - test loss: 9.2804 - train acc: 0.4022 - test acc: 0.4658 - 0m 8s\n",
      "batch: 500/1875 - train loss: 7.8247 - test loss: 6.2911 - train acc: 0.5216 - test acc: 0.6210 - 0m 11s\n",
      "batch: 600/1875 - train loss: 5.5894 - test loss: 4.7744 - train acc: 0.6731 - test acc: 0.7299 - 0m 13s\n",
      "batch: 700/1875 - train loss: 4.4257 - test loss: 4.0732 - train acc: 0.7553 - test acc: 0.7752 - 0m 16s\n",
      "batch: 800/1875 - train loss: 4.0489 - test loss: 3.7958 - train acc: 0.7834 - test acc: 0.7974 - 0m 19s\n",
      "batch: 900/1875 - train loss: 3.8365 - test loss: 3.5314 - train acc: 0.7865 - test acc: 0.8124 - 0m 21s\n",
      "batch: 1000/1875 - train loss: 3.4666 - test loss: 3.2792 - train acc: 0.8115 - test acc: 0.8251 - 0m 24s\n",
      "batch: 1100/1875 - train loss: 3.2396 - test loss: 3.0030 - train acc: 0.8256 - test acc: 0.8407 - 0m 26s\n",
      "batch: 1200/1875 - train loss: 3.0583 - test loss: 2.8622 - train acc: 0.8374 - test acc: 0.8454 - 0m 29s\n",
      "batch: 1300/1875 - train loss: 2.9265 - test loss: 2.6039 - train acc: 0.8450 - test acc: 0.8661 - 0m 32s\n",
      "batch: 1400/1875 - train loss: 2.5929 - test loss: 2.5062 - train acc: 0.8600 - test acc: 0.8701 - 0m 34s\n",
      "batch: 1500/1875 - train loss: 2.6420 - test loss: 2.5767 - train acc: 0.8618 - test acc: 0.8668 - 0m 37s\n",
      "batch: 1600/1875 - train loss: 2.4758 - test loss: 2.5100 - train acc: 0.8725 - test acc: 0.8632 - 0m 40s\n",
      "batch: 1700/1875 - train loss: 2.4608 - test loss: 2.3011 - train acc: 0.8775 - test acc: 0.8777 - 0m 42s\n",
      "batch: 1800/1875 - train loss: 2.3641 - test loss: 2.2001 - train acc: 0.8791 - test acc: 0.8810 - 0m 45s\n",
      "batch: 1875/1875 - train loss: 2.3181 - test loss: 2.1838 - train acc: 0.8785 - test acc: 0.8864 - 0m 47s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 2/10\n",
      "batch: 100/1875 - train loss: 2.3659 - test loss: 2.1263 - train acc: 0.8728 - test acc: 0.8876 - 0m 50s\n",
      "batch: 200/1875 - train loss: 2.2182 - test loss: 2.1586 - train acc: 0.8873 - test acc: 0.8855 - 0m 53s\n",
      "batch: 300/1875 - train loss: 2.0934 - test loss: 2.0924 - train acc: 0.8922 - test acc: 0.8900 - 0m 55s\n",
      "batch: 400/1875 - train loss: 2.2400 - test loss: 2.0322 - train acc: 0.8841 - test acc: 0.8936 - 0m 58s\n",
      "batch: 500/1875 - train loss: 2.1216 - test loss: 2.0499 - train acc: 0.8904 - test acc: 0.8914 - 1m 0s\n",
      "batch: 600/1875 - train loss: 2.0348 - test loss: 1.9508 - train acc: 0.8951 - test acc: 0.8963 - 1m 3s\n",
      "batch: 700/1875 - train loss: 2.0586 - test loss: 2.0369 - train acc: 0.8922 - test acc: 0.8927 - 1m 5s\n",
      "batch: 800/1875 - train loss: 2.2369 - test loss: 1.9657 - train acc: 0.8806 - test acc: 0.8966 - 1m 8s\n",
      "batch: 900/1875 - train loss: 2.0533 - test loss: 1.9831 - train acc: 0.8866 - test acc: 0.8956 - 1m 11s\n",
      "batch: 1000/1875 - train loss: 2.0926 - test loss: 1.8487 - train acc: 0.8916 - test acc: 0.9005 - 1m 13s\n",
      "batch: 1100/1875 - train loss: 1.8458 - test loss: 1.8193 - train acc: 0.9095 - test acc: 0.9045 - 1m 16s\n",
      "batch: 1200/1875 - train loss: 1.9796 - test loss: 1.7731 - train acc: 0.8932 - test acc: 0.9058 - 1m 19s\n",
      "batch: 1300/1875 - train loss: 1.8692 - test loss: 1.8781 - train acc: 0.9007 - test acc: 0.9005 - 1m 21s\n",
      "batch: 1400/1875 - train loss: 1.9231 - test loss: 1.7522 - train acc: 0.9032 - test acc: 0.9073 - 1m 24s\n",
      "batch: 1500/1875 - train loss: 1.5919 - test loss: 1.7154 - train acc: 0.9185 - test acc: 0.9109 - 1m 27s\n",
      "batch: 1600/1875 - train loss: 1.8535 - test loss: 1.6943 - train acc: 0.9054 - test acc: 0.9117 - 1m 29s\n",
      "batch: 1700/1875 - train loss: 2.0280 - test loss: 1.7720 - train acc: 0.9001 - test acc: 0.9072 - 1m 32s\n",
      "batch: 1800/1875 - train loss: 1.7698 - test loss: 1.6808 - train acc: 0.9104 - test acc: 0.9110 - 1m 35s\n",
      "batch: 1875/1875 - train loss: 1.6376 - test loss: 1.7220 - train acc: 0.9145 - test acc: 0.9136 - 1m 37s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 3/10\n",
      "batch: 100/1875 - train loss: 1.7715 - test loss: 1.6528 - train acc: 0.9088 - test acc: 0.9095 - 1m 39s\n",
      "batch: 200/1875 - train loss: 1.7138 - test loss: 1.6863 - train acc: 0.9161 - test acc: 0.9088 - 1m 42s\n",
      "batch: 300/1875 - train loss: 1.8439 - test loss: 1.6867 - train acc: 0.8991 - test acc: 0.9111 - 1m 44s\n",
      "batch: 400/1875 - train loss: 1.7032 - test loss: 1.5920 - train acc: 0.9136 - test acc: 0.9164 - 1m 47s\n",
      "batch: 500/1875 - train loss: 1.5156 - test loss: 1.5666 - train acc: 0.9251 - test acc: 0.9176 - 1m 50s\n",
      "batch: 600/1875 - train loss: 1.6672 - test loss: 1.6034 - train acc: 0.9195 - test acc: 0.9149 - 1m 53s\n",
      "batch: 700/1875 - train loss: 1.6674 - test loss: 1.5383 - train acc: 0.9167 - test acc: 0.9206 - 1m 55s\n",
      "batch: 800/1875 - train loss: 1.6002 - test loss: 1.5503 - train acc: 0.9205 - test acc: 0.9173 - 1m 58s\n",
      "batch: 900/1875 - train loss: 1.6380 - test loss: 1.5933 - train acc: 0.9136 - test acc: 0.9175 - 2m 1s\n",
      "batch: 1000/1875 - train loss: 1.2688 - test loss: 1.5040 - train acc: 0.9333 - test acc: 0.9218 - 2m 3s\n",
      "batch: 1100/1875 - train loss: 1.6174 - test loss: 1.5358 - train acc: 0.9132 - test acc: 0.9208 - 2m 6s\n",
      "batch: 1200/1875 - train loss: 1.6100 - test loss: 1.4604 - train acc: 0.9148 - test acc: 0.9242 - 2m 9s\n",
      "batch: 1300/1875 - train loss: 1.5470 - test loss: 1.5162 - train acc: 0.9232 - test acc: 0.9200 - 2m 11s\n",
      "batch: 1400/1875 - train loss: 1.6783 - test loss: 1.5610 - train acc: 0.9201 - test acc: 0.9162 - 2m 14s\n",
      "batch: 1500/1875 - train loss: 1.3245 - test loss: 1.4214 - train acc: 0.9286 - test acc: 0.9248 - 2m 16s\n",
      "batch: 1600/1875 - train loss: 1.5571 - test loss: 1.4324 - train acc: 0.9177 - test acc: 0.9231 - 2m 19s\n",
      "batch: 1700/1875 - train loss: 1.4371 - test loss: 1.3997 - train acc: 0.9258 - test acc: 0.9266 - 2m 22s\n",
      "batch: 1800/1875 - train loss: 1.4489 - test loss: 1.3678 - train acc: 0.9252 - test acc: 0.9261 - 2m 25s\n",
      "batch: 1875/1875 - train loss: 1.4975 - test loss: 1.4317 - train acc: 0.9186 - test acc: 0.9279 - 2m 27s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 4/10\n",
      "batch: 100/1875 - train loss: 1.2414 - test loss: 1.3269 - train acc: 0.9399 - test acc: 0.9303 - 2m 30s\n",
      "batch: 200/1875 - train loss: 1.3913 - test loss: 1.3504 - train acc: 0.9273 - test acc: 0.9280 - 2m 32s\n",
      "batch: 300/1875 - train loss: 1.5249 - test loss: 1.3428 - train acc: 0.9195 - test acc: 0.9270 - 2m 35s\n",
      "batch: 400/1875 - train loss: 1.4331 - test loss: 1.3510 - train acc: 0.9270 - test acc: 0.9271 - 2m 37s\n",
      "batch: 500/1875 - train loss: 1.5894 - test loss: 1.4908 - train acc: 0.9207 - test acc: 0.9218 - 2m 40s\n",
      "batch: 600/1875 - train loss: 1.3976 - test loss: 1.3943 - train acc: 0.9273 - test acc: 0.9278 - 2m 42s\n",
      "batch: 700/1875 - train loss: 1.3899 - test loss: 1.3422 - train acc: 0.9299 - test acc: 0.9265 - 2m 45s\n",
      "batch: 800/1875 - train loss: 1.3191 - test loss: 1.3187 - train acc: 0.9292 - test acc: 0.9304 - 2m 47s\n",
      "batch: 900/1875 - train loss: 1.4030 - test loss: 1.3169 - train acc: 0.9323 - test acc: 0.9297 - 2m 50s\n",
      "batch: 1000/1875 - train loss: 1.4305 - test loss: 1.3710 - train acc: 0.9270 - test acc: 0.9275 - 2m 53s\n",
      "batch: 1100/1875 - train loss: 1.2487 - test loss: 1.3022 - train acc: 0.9355 - test acc: 0.9306 - 2m 56s\n",
      "batch: 1200/1875 - train loss: 1.3129 - test loss: 1.2945 - train acc: 0.9276 - test acc: 0.9325 - 2m 58s\n",
      "batch: 1300/1875 - train loss: 1.2007 - test loss: 1.3902 - train acc: 0.9330 - test acc: 0.9244 - 3m 1s\n",
      "batch: 1400/1875 - train loss: 1.4533 - test loss: 1.2976 - train acc: 0.9283 - test acc: 0.9283 - 3m 3s\n",
      "batch: 1500/1875 - train loss: 1.3061 - test loss: 1.6009 - train acc: 0.9283 - test acc: 0.9178 - 3m 6s\n",
      "batch: 1600/1875 - train loss: 1.3355 - test loss: 1.3289 - train acc: 0.9327 - test acc: 0.9273 - 3m 8s\n",
      "batch: 1700/1875 - train loss: 1.3106 - test loss: 1.2628 - train acc: 0.9348 - test acc: 0.9337 - 3m 11s\n",
      "batch: 1800/1875 - train loss: 1.3496 - test loss: 1.2165 - train acc: 0.9358 - test acc: 0.9350 - 3m 14s\n",
      "batch: 1875/1875 - train loss: 1.3225 - test loss: 1.2706 - train acc: 0.9339 - test acc: 0.9302 - 3m 16s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 5/10\n",
      "batch: 100/1875 - train loss: 1.1294 - test loss: 1.2718 - train acc: 0.9408 - test acc: 0.9334 - 3m 19s\n",
      "batch: 200/1875 - train loss: 1.2619 - test loss: 1.3232 - train acc: 0.9304 - test acc: 0.9287 - 3m 21s\n",
      "batch: 300/1875 - train loss: 1.1425 - test loss: 1.2258 - train acc: 0.9380 - test acc: 0.9347 - 3m 24s\n",
      "batch: 400/1875 - train loss: 1.2290 - test loss: 1.3294 - train acc: 0.9358 - test acc: 0.9310 - 3m 27s\n",
      "batch: 500/1875 - train loss: 1.1714 - test loss: 1.2415 - train acc: 0.9377 - test acc: 0.9354 - 3m 30s\n",
      "batch: 600/1875 - train loss: 1.1743 - test loss: 1.2559 - train acc: 0.9399 - test acc: 0.9341 - 3m 32s\n",
      "batch: 700/1875 - train loss: 1.3004 - test loss: 1.2188 - train acc: 0.9326 - test acc: 0.9350 - 3m 34s\n",
      "batch: 800/1875 - train loss: 1.2796 - test loss: 1.2175 - train acc: 0.9396 - test acc: 0.9347 - 3m 37s\n",
      "batch: 900/1875 - train loss: 1.1085 - test loss: 1.2445 - train acc: 0.9424 - test acc: 0.9348 - 3m 40s\n",
      "batch: 1000/1875 - train loss: 1.1835 - test loss: 1.2026 - train acc: 0.9348 - test acc: 0.9362 - 3m 42s\n",
      "batch: 1100/1875 - train loss: 1.2437 - test loss: 1.1698 - train acc: 0.9389 - test acc: 0.9370 - 3m 45s\n",
      "batch: 1200/1875 - train loss: 1.1468 - test loss: 1.2231 - train acc: 0.9458 - test acc: 0.9340 - 3m 48s\n",
      "batch: 1300/1875 - train loss: 1.1666 - test loss: 1.1872 - train acc: 0.9380 - test acc: 0.9363 - 3m 50s\n",
      "batch: 1400/1875 - train loss: 1.1450 - test loss: 1.3415 - train acc: 0.9402 - test acc: 0.9319 - 3m 53s\n",
      "batch: 1500/1875 - train loss: 1.3568 - test loss: 1.1764 - train acc: 0.9324 - test acc: 0.9381 - 3m 55s\n",
      "batch: 1600/1875 - train loss: 1.3372 - test loss: 1.2737 - train acc: 0.9311 - test acc: 0.9318 - 3m 59s\n",
      "batch: 1700/1875 - train loss: 1.2864 - test loss: 1.1979 - train acc: 0.9320 - test acc: 0.9336 - 4m 1s\n",
      "batch: 1800/1875 - train loss: 0.9844 - test loss: 1.1381 - train acc: 0.9492 - test acc: 0.9397 - 4m 4s\n",
      "batch: 1875/1875 - train loss: 1.2836 - test loss: 1.2797 - train acc: 0.9345 - test acc: 0.9328 - 4m 6s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 6/10\n",
      "batch: 100/1875 - train loss: 1.2997 - test loss: 1.1379 - train acc: 0.9336 - test acc: 0.9390 - 4m 9s\n",
      "batch: 200/1875 - train loss: 1.1793 - test loss: 1.1681 - train acc: 0.9401 - test acc: 0.9359 - 4m 11s\n",
      "batch: 300/1875 - train loss: 1.0447 - test loss: 1.1118 - train acc: 0.9446 - test acc: 0.9406 - 4m 14s\n",
      "batch: 400/1875 - train loss: 1.1684 - test loss: 1.1377 - train acc: 0.9396 - test acc: 0.9393 - 4m 16s\n",
      "batch: 500/1875 - train loss: 1.1502 - test loss: 1.1667 - train acc: 0.9402 - test acc: 0.9357 - 4m 19s\n",
      "batch: 600/1875 - train loss: 1.0205 - test loss: 1.1181 - train acc: 0.9470 - test acc: 0.9377 - 4m 21s\n",
      "batch: 700/1875 - train loss: 1.0881 - test loss: 1.1145 - train acc: 0.9487 - test acc: 0.9416 - 4m 24s\n",
      "batch: 800/1875 - train loss: 1.1129 - test loss: 1.1885 - train acc: 0.9414 - test acc: 0.9348 - 4m 26s\n",
      "batch: 900/1875 - train loss: 1.1694 - test loss: 1.0954 - train acc: 0.9383 - test acc: 0.9403 - 4m 29s\n",
      "batch: 1000/1875 - train loss: 1.0718 - test loss: 1.0713 - train acc: 0.9477 - test acc: 0.9437 - 4m 32s\n",
      "batch: 1100/1875 - train loss: 1.0223 - test loss: 1.1299 - train acc: 0.9517 - test acc: 0.9403 - 4m 35s\n",
      "batch: 1200/1875 - train loss: 1.0062 - test loss: 1.1174 - train acc: 0.9420 - test acc: 0.9406 - 4m 37s\n",
      "batch: 1300/1875 - train loss: 1.0539 - test loss: 1.0801 - train acc: 0.9426 - test acc: 0.9419 - 4m 40s\n",
      "batch: 1400/1875 - train loss: 1.0664 - test loss: 1.0700 - train acc: 0.9445 - test acc: 0.9421 - 4m 43s\n",
      "batch: 1500/1875 - train loss: 1.1180 - test loss: 1.0466 - train acc: 0.9436 - test acc: 0.9456 - 4m 45s\n",
      "batch: 1600/1875 - train loss: 1.1155 - test loss: 1.0783 - train acc: 0.9426 - test acc: 0.9433 - 4m 48s\n",
      "batch: 1700/1875 - train loss: 1.0140 - test loss: 1.1137 - train acc: 0.9502 - test acc: 0.9408 - 4m 50s\n",
      "batch: 1800/1875 - train loss: 0.9606 - test loss: 1.0968 - train acc: 0.9458 - test acc: 0.9406 - 4m 53s\n",
      "batch: 1875/1875 - train loss: 1.1750 - test loss: 1.0799 - train acc: 0.9374 - test acc: 0.9431 - 4m 55s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 7/10\n",
      "batch: 100/1875 - train loss: 0.9847 - test loss: 1.0503 - train acc: 0.9480 - test acc: 0.9446 - 4m 58s\n",
      "time is up! finishing training\n",
      "batch: 187/1875 - train loss: 0.9968 - test loss: 1.0698 - train acc: 0.9467 - test acc: 0.9422 - 5m 1s\n",
      "GPU memory used: 0.01 GB - max: 0.01 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "testing: partition-size: 32 - buffer-size: 64 - block_updates: 512\n",
      "generating MNIST data with 10 classes\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 16]          12,560\n",
      "              ReLU-3                   [-1, 16]               0\n",
      "            Linear-4                   [-1, 16]             272\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "            Linear-6                   [-1, 16]             272\n",
      "              ReLU-7                   [-1, 16]               0\n",
      "            Linear-8                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n",
      "FisherPartitioner: param: 12544 - partition: 32 - nº part: 392 - block updates: 392\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 160 - partition: 32 - nº part: 5 - block updates: 5\n",
      "FisherPartitioner: param: 10 - partition: 32 - nº part: 1 - block updates: 1\n",
      "total partitions: 417 - effective block updates: 417\n",
      "initializing buffers and inverses...\n",
      "partition 1/417\n",
      "partition 417/417\n",
      "starting epoch: 1/10\n",
      "batch: 100/1875 - train loss: 13.0039 - test loss: 12.9842 - train acc: 0.1137 - test acc: 0.1492 - 0m 0s\n",
      "batch: 200/1875 - train loss: 12.9327 - test loss: 12.8621 - train acc: 0.2313 - test acc: 0.2784 - 0m 3s\n",
      "batch: 300/1875 - train loss: 12.7414 - test loss: 12.5548 - train acc: 0.2966 - test acc: 0.2763 - 0m 5s\n",
      "batch: 400/1875 - train loss: 12.1606 - test loss: 11.4929 - train acc: 0.3166 - test acc: 0.3711 - 0m 8s\n",
      "batch: 500/1875 - train loss: 10.3986 - test loss: 9.1698 - train acc: 0.4034 - test acc: 0.4556 - 0m 11s\n",
      "batch: 600/1875 - train loss: 8.1092 - test loss: 6.8612 - train acc: 0.5279 - test acc: 0.6207 - 0m 13s\n",
      "batch: 700/1875 - train loss: 6.2462 - test loss: 5.4354 - train acc: 0.6507 - test acc: 0.7092 - 0m 15s\n",
      "batch: 800/1875 - train loss: 4.9439 - test loss: 4.3843 - train acc: 0.7325 - test acc: 0.7428 - 0m 18s\n",
      "batch: 900/1875 - train loss: 4.2219 - test loss: 3.6910 - train acc: 0.7781 - test acc: 0.8023 - 0m 20s\n",
      "batch: 1000/1875 - train loss: 3.4252 - test loss: 3.1080 - train acc: 0.8140 - test acc: 0.8408 - 0m 23s\n",
      "batch: 1100/1875 - train loss: 2.9810 - test loss: 2.8499 - train acc: 0.8412 - test acc: 0.8548 - 0m 26s\n",
      "batch: 1200/1875 - train loss: 2.9796 - test loss: 2.6975 - train acc: 0.8484 - test acc: 0.8596 - 0m 29s\n",
      "batch: 1300/1875 - train loss: 2.8743 - test loss: 2.6518 - train acc: 0.8609 - test acc: 0.8623 - 0m 31s\n",
      "batch: 1400/1875 - train loss: 2.7851 - test loss: 2.5416 - train acc: 0.8644 - test acc: 0.8644 - 0m 34s\n",
      "batch: 1500/1875 - train loss: 2.5615 - test loss: 2.4678 - train acc: 0.8631 - test acc: 0.8685 - 0m 37s\n",
      "batch: 1600/1875 - train loss: 2.4788 - test loss: 2.4252 - train acc: 0.8668 - test acc: 0.8762 - 0m 39s\n",
      "batch: 1700/1875 - train loss: 2.3249 - test loss: 2.3039 - train acc: 0.8775 - test acc: 0.8777 - 0m 42s\n",
      "batch: 1800/1875 - train loss: 2.4810 - test loss: 2.2640 - train acc: 0.8781 - test acc: 0.8779 - 0m 45s\n",
      "batch: 1875/1875 - train loss: 2.4291 - test loss: 2.3158 - train acc: 0.8706 - test acc: 0.8777 - 0m 47s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 2/10\n",
      "batch: 100/1875 - train loss: 2.4707 - test loss: 2.1665 - train acc: 0.8819 - test acc: 0.8860 - 0m 49s\n",
      "batch: 200/1875 - train loss: 2.1753 - test loss: 2.1236 - train acc: 0.8869 - test acc: 0.8886 - 0m 52s\n",
      "batch: 300/1875 - train loss: 2.3355 - test loss: 2.1510 - train acc: 0.8794 - test acc: 0.8853 - 0m 55s\n",
      "batch: 400/1875 - train loss: 2.2729 - test loss: 2.0604 - train acc: 0.8831 - test acc: 0.8907 - 0m 57s\n",
      "batch: 500/1875 - train loss: 2.0800 - test loss: 1.9697 - train acc: 0.8935 - test acc: 0.8944 - 1m 0s\n",
      "batch: 600/1875 - train loss: 2.0109 - test loss: 2.0776 - train acc: 0.8947 - test acc: 0.8882 - 1m 3s\n",
      "batch: 700/1875 - train loss: 2.0465 - test loss: 1.9127 - train acc: 0.8900 - test acc: 0.8974 - 1m 6s\n",
      "batch: 800/1875 - train loss: 2.1090 - test loss: 1.8868 - train acc: 0.8947 - test acc: 0.9001 - 1m 8s\n",
      "batch: 900/1875 - train loss: 1.9460 - test loss: 1.9668 - train acc: 0.8941 - test acc: 0.8948 - 1m 10s\n",
      "batch: 1000/1875 - train loss: 1.9626 - test loss: 1.8752 - train acc: 0.8982 - test acc: 0.9016 - 1m 13s\n",
      "batch: 1100/1875 - train loss: 1.8034 - test loss: 1.7805 - train acc: 0.9114 - test acc: 0.9041 - 1m 16s\n",
      "batch: 1200/1875 - train loss: 2.0013 - test loss: 1.7921 - train acc: 0.8916 - test acc: 0.9019 - 1m 18s\n",
      "batch: 1300/1875 - train loss: 1.7045 - test loss: 1.7054 - train acc: 0.9070 - test acc: 0.9088 - 1m 21s\n",
      "batch: 1400/1875 - train loss: 1.5984 - test loss: 1.6810 - train acc: 0.9151 - test acc: 0.9069 - 1m 23s\n",
      "batch: 1500/1875 - train loss: 1.7049 - test loss: 1.7632 - train acc: 0.9054 - test acc: 0.9042 - 1m 26s\n",
      "batch: 1600/1875 - train loss: 1.8172 - test loss: 1.6861 - train acc: 0.9082 - test acc: 0.9087 - 1m 29s\n",
      "batch: 1700/1875 - train loss: 1.5991 - test loss: 1.5818 - train acc: 0.9195 - test acc: 0.9143 - 1m 31s\n",
      "batch: 1800/1875 - train loss: 1.6179 - test loss: 1.5970 - train acc: 0.9148 - test acc: 0.9157 - 1m 34s\n",
      "batch: 1875/1875 - train loss: 1.5515 - test loss: 1.5345 - train acc: 0.9189 - test acc: 0.9171 - 1m 36s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 3/10\n",
      "batch: 100/1875 - train loss: 1.5709 - test loss: 1.5264 - train acc: 0.9133 - test acc: 0.9215 - 1m 39s\n",
      "batch: 200/1875 - train loss: 1.6678 - test loss: 1.5114 - train acc: 0.9148 - test acc: 0.9204 - 1m 42s\n",
      "batch: 300/1875 - train loss: 1.5579 - test loss: 1.5181 - train acc: 0.9217 - test acc: 0.9189 - 1m 44s\n",
      "batch: 400/1875 - train loss: 1.4592 - test loss: 1.5037 - train acc: 0.9202 - test acc: 0.9201 - 1m 47s\n",
      "batch: 500/1875 - train loss: 1.6172 - test loss: 1.5287 - train acc: 0.9214 - test acc: 0.9167 - 1m 50s\n",
      "batch: 600/1875 - train loss: 1.5221 - test loss: 1.4947 - train acc: 0.9213 - test acc: 0.9201 - 1m 52s\n",
      "batch: 700/1875 - train loss: 1.5092 - test loss: 1.4650 - train acc: 0.9236 - test acc: 0.9237 - 1m 54s\n",
      "batch: 800/1875 - train loss: 1.4211 - test loss: 1.4835 - train acc: 0.9245 - test acc: 0.9193 - 1m 57s\n",
      "batch: 900/1875 - train loss: 1.4320 - test loss: 1.3681 - train acc: 0.9154 - test acc: 0.9273 - 2m 0s\n",
      "batch: 1000/1875 - train loss: 1.4527 - test loss: 1.3538 - train acc: 0.9280 - test acc: 0.9279 - 2m 2s\n",
      "batch: 1100/1875 - train loss: 1.2260 - test loss: 1.4059 - train acc: 0.9383 - test acc: 0.9245 - 2m 5s\n",
      "batch: 1200/1875 - train loss: 1.4211 - test loss: 1.4751 - train acc: 0.9182 - test acc: 0.9201 - 2m 8s\n",
      "batch: 1300/1875 - train loss: 1.3442 - test loss: 1.3860 - train acc: 0.9321 - test acc: 0.9258 - 2m 10s\n",
      "batch: 1400/1875 - train loss: 1.2593 - test loss: 1.3320 - train acc: 0.9336 - test acc: 0.9288 - 2m 13s\n",
      "batch: 1500/1875 - train loss: 1.4568 - test loss: 1.2791 - train acc: 0.9217 - test acc: 0.9320 - 2m 16s\n",
      "batch: 1600/1875 - train loss: 1.3251 - test loss: 1.2878 - train acc: 0.9358 - test acc: 0.9308 - 2m 18s\n",
      "batch: 1700/1875 - train loss: 1.3901 - test loss: 1.4277 - train acc: 0.9333 - test acc: 0.9234 - 2m 21s\n",
      "batch: 1800/1875 - train loss: 1.2755 - test loss: 1.3127 - train acc: 0.9298 - test acc: 0.9283 - 2m 24s\n",
      "batch: 1875/1875 - train loss: 1.3790 - test loss: 1.2337 - train acc: 0.9266 - test acc: 0.9340 - 2m 26s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 4/10\n",
      "batch: 100/1875 - train loss: 1.2286 - test loss: 1.2926 - train acc: 0.9345 - test acc: 0.9319 - 2m 28s\n",
      "batch: 200/1875 - train loss: 1.2113 - test loss: 1.2867 - train acc: 0.9358 - test acc: 0.9330 - 2m 31s\n",
      "batch: 300/1875 - train loss: 1.2613 - test loss: 1.3900 - train acc: 0.9333 - test acc: 0.9258 - 2m 34s\n",
      "batch: 400/1875 - train loss: 1.2828 - test loss: 1.2038 - train acc: 0.9317 - test acc: 0.9360 - 2m 37s\n",
      "batch: 500/1875 - train loss: 1.2418 - test loss: 1.2921 - train acc: 0.9342 - test acc: 0.9297 - 2m 39s\n",
      "batch: 600/1875 - train loss: 1.2925 - test loss: 1.3071 - train acc: 0.9339 - test acc: 0.9282 - 2m 42s\n",
      "batch: 700/1875 - train loss: 1.2519 - test loss: 1.1913 - train acc: 0.9383 - test acc: 0.9361 - 2m 45s\n",
      "batch: 800/1875 - train loss: 1.1530 - test loss: 1.2286 - train acc: 0.9390 - test acc: 0.9348 - 2m 47s\n",
      "batch: 900/1875 - train loss: 1.2164 - test loss: 1.1709 - train acc: 0.9380 - test acc: 0.9374 - 2m 50s\n",
      "batch: 1000/1875 - train loss: 1.1790 - test loss: 1.2727 - train acc: 0.9405 - test acc: 0.9312 - 2m 52s\n",
      "batch: 1100/1875 - train loss: 1.3133 - test loss: 1.1484 - train acc: 0.9320 - test acc: 0.9383 - 2m 55s\n",
      "batch: 1200/1875 - train loss: 1.1680 - test loss: 1.2522 - train acc: 0.9364 - test acc: 0.9325 - 2m 58s\n",
      "batch: 1300/1875 - train loss: 1.1865 - test loss: 1.2216 - train acc: 0.9367 - test acc: 0.9346 - 3m 0s\n",
      "batch: 1400/1875 - train loss: 1.1611 - test loss: 1.1725 - train acc: 0.9401 - test acc: 0.9386 - 3m 3s\n",
      "batch: 1500/1875 - train loss: 1.2469 - test loss: 1.1084 - train acc: 0.9364 - test acc: 0.9396 - 3m 5s\n",
      "batch: 1600/1875 - train loss: 1.1507 - test loss: 1.2040 - train acc: 0.9355 - test acc: 0.9332 - 3m 9s\n",
      "batch: 1700/1875 - train loss: 1.1539 - test loss: 1.1010 - train acc: 0.9380 - test acc: 0.9398 - 3m 11s\n",
      "batch: 1800/1875 - train loss: 1.1676 - test loss: 1.1270 - train acc: 0.9336 - test acc: 0.9393 - 3m 14s\n",
      "batch: 1875/1875 - train loss: 1.0832 - test loss: 1.1910 - train acc: 0.9411 - test acc: 0.9355 - 3m 16s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 5/10\n",
      "batch: 100/1875 - train loss: 1.0886 - test loss: 1.2077 - train acc: 0.9395 - test acc: 0.9375 - 3m 19s\n",
      "batch: 200/1875 - train loss: 1.0492 - test loss: 1.2428 - train acc: 0.9477 - test acc: 0.9321 - 3m 21s\n",
      "batch: 300/1875 - train loss: 1.0614 - test loss: 1.2601 - train acc: 0.9442 - test acc: 0.9339 - 3m 24s\n",
      "batch: 400/1875 - train loss: 1.1188 - test loss: 1.1516 - train acc: 0.9417 - test acc: 0.9388 - 3m 26s\n",
      "batch: 500/1875 - train loss: 1.1102 - test loss: 1.1200 - train acc: 0.9436 - test acc: 0.9429 - 3m 29s\n",
      "batch: 600/1875 - train loss: 1.2829 - test loss: 1.2073 - train acc: 0.9308 - test acc: 0.9353 - 3m 32s\n",
      "batch: 700/1875 - train loss: 1.0969 - test loss: 1.0694 - train acc: 0.9392 - test acc: 0.9417 - 3m 34s\n",
      "batch: 800/1875 - train loss: 1.0639 - test loss: 1.1698 - train acc: 0.9436 - test acc: 0.9370 - 3m 37s\n",
      "batch: 900/1875 - train loss: 0.9658 - test loss: 1.1245 - train acc: 0.9480 - test acc: 0.9393 - 3m 40s\n",
      "batch: 1000/1875 - train loss: 1.0876 - test loss: 1.1225 - train acc: 0.9424 - test acc: 0.9410 - 3m 43s\n",
      "batch: 1100/1875 - train loss: 1.2474 - test loss: 1.0238 - train acc: 0.9351 - test acc: 0.9432 - 3m 45s\n",
      "batch: 1200/1875 - train loss: 1.1276 - test loss: 1.0894 - train acc: 0.9392 - test acc: 0.9418 - 3m 48s\n",
      "batch: 1300/1875 - train loss: 1.1734 - test loss: 1.1370 - train acc: 0.9380 - test acc: 0.9396 - 3m 50s\n",
      "batch: 1400/1875 - train loss: 1.0892 - test loss: 1.1253 - train acc: 0.9408 - test acc: 0.9400 - 3m 53s\n",
      "batch: 1500/1875 - train loss: 1.0766 - test loss: 1.0508 - train acc: 0.9421 - test acc: 0.9428 - 3m 55s\n",
      "batch: 1600/1875 - train loss: 1.0620 - test loss: 1.0573 - train acc: 0.9418 - test acc: 0.9426 - 3m 58s\n",
      "batch: 1700/1875 - train loss: 1.0766 - test loss: 1.0160 - train acc: 0.9474 - test acc: 0.9441 - 4m 0s\n",
      "batch: 1800/1875 - train loss: 1.0808 - test loss: 1.1257 - train acc: 0.9389 - test acc: 0.9387 - 4m 3s\n",
      "batch: 1875/1875 - train loss: 0.9919 - test loss: 1.0962 - train acc: 0.9483 - test acc: 0.9417 - 4m 5s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 6/10\n",
      "batch: 100/1875 - train loss: 1.0475 - test loss: 1.0486 - train acc: 0.9452 - test acc: 0.9418 - 4m 8s\n",
      "batch: 200/1875 - train loss: 0.9690 - test loss: 1.1127 - train acc: 0.9508 - test acc: 0.9391 - 4m 10s\n",
      "batch: 300/1875 - train loss: 1.0072 - test loss: 1.0446 - train acc: 0.9433 - test acc: 0.9443 - 4m 14s\n",
      "batch: 400/1875 - train loss: 1.0822 - test loss: 1.0904 - train acc: 0.9452 - test acc: 0.9425 - 4m 17s\n",
      "batch: 500/1875 - train loss: 1.0245 - test loss: 1.1079 - train acc: 0.9461 - test acc: 0.9451 - 4m 19s\n",
      "batch: 600/1875 - train loss: 0.9667 - test loss: 1.0486 - train acc: 0.9492 - test acc: 0.9435 - 4m 21s\n",
      "batch: 700/1875 - train loss: 1.0538 - test loss: 1.0295 - train acc: 0.9427 - test acc: 0.9443 - 4m 24s\n",
      "batch: 800/1875 - train loss: 1.0463 - test loss: 1.0274 - train acc: 0.9446 - test acc: 0.9437 - 4m 27s\n",
      "batch: 900/1875 - train loss: 0.9253 - test loss: 1.0317 - train acc: 0.9464 - test acc: 0.9447 - 4m 29s\n",
      "batch: 1000/1875 - train loss: 0.9610 - test loss: 1.0605 - train acc: 0.9518 - test acc: 0.9434 - 4m 32s\n",
      "batch: 1100/1875 - train loss: 1.0747 - test loss: 1.0166 - train acc: 0.9445 - test acc: 0.9468 - 4m 35s\n",
      "batch: 1200/1875 - train loss: 1.0504 - test loss: 1.0443 - train acc: 0.9443 - test acc: 0.9445 - 4m 37s\n",
      "batch: 1300/1875 - train loss: 1.0241 - test loss: 1.0312 - train acc: 0.9452 - test acc: 0.9460 - 4m 40s\n",
      "batch: 1400/1875 - train loss: 1.0306 - test loss: 1.0054 - train acc: 0.9452 - test acc: 0.9466 - 4m 42s\n",
      "batch: 1500/1875 - train loss: 0.9965 - test loss: 1.0051 - train acc: 0.9492 - test acc: 0.9461 - 4m 46s\n",
      "batch: 1600/1875 - train loss: 0.9358 - test loss: 1.0818 - train acc: 0.9480 - test acc: 0.9416 - 4m 48s\n",
      "batch: 1700/1875 - train loss: 1.0535 - test loss: 1.0335 - train acc: 0.9461 - test acc: 0.9439 - 4m 51s\n",
      "batch: 1800/1875 - train loss: 0.8921 - test loss: 1.0061 - train acc: 0.9493 - test acc: 0.9450 - 4m 53s\n",
      "batch: 1875/1875 - train loss: 0.9494 - test loss: 0.9556 - train acc: 0.9480 - test acc: 0.9496 - 4m 55s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 7/10\n",
      "batch: 100/1875 - train loss: 1.0056 - test loss: 0.9888 - train acc: 0.9508 - test acc: 0.9474 - 4m 58s\n",
      "time is up! finishing training\n",
      "batch: 184/1875 - train loss: 0.9737 - test loss: 1.0345 - train acc: 0.9483 - test acc: 0.9440 - 5m 1s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "\n",
      "\n",
      "-----------------------------------\n",
      "testing: partition-size: 32 - buffer-size: 64 - block_updates: 2048\n",
      "generating MNIST data with 10 classes\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "            Linear-2                   [-1, 16]          12,560\n",
      "              ReLU-3                   [-1, 16]               0\n",
      "            Linear-4                   [-1, 16]             272\n",
      "              ReLU-5                   [-1, 16]               0\n",
      "            Linear-6                   [-1, 16]             272\n",
      "              ReLU-7                   [-1, 16]               0\n",
      "            Linear-8                   [-1, 10]             170\n",
      "================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n",
      "FisherPartitioner: param: 12544 - partition: 32 - nº part: 392 - block updates: 392\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 256 - partition: 32 - nº part: 8 - block updates: 8\n",
      "FisherPartitioner: param: 16 - partition: 32 - nº part: 1 - block updates: 1\n",
      "FisherPartitioner: param: 160 - partition: 32 - nº part: 5 - block updates: 5\n",
      "FisherPartitioner: param: 10 - partition: 32 - nº part: 1 - block updates: 1\n",
      "total partitions: 417 - effective block updates: 417\n",
      "initializing buffers and inverses...\n",
      "partition 1/417\n",
      "partition 417/417\n",
      "starting epoch: 1/10\n",
      "batch: 100/1875 - train loss: 13.0570 - test loss: 13.0195 - train acc: 0.1224 - test acc: 0.1372 - 0m 0s\n",
      "batch: 200/1875 - train loss: 12.9484 - test loss: 12.9169 - train acc: 0.1338 - test acc: 0.1092 - 0m 3s\n",
      "batch: 300/1875 - train loss: 12.8295 - test loss: 12.7314 - train acc: 0.1250 - test acc: 0.1564 - 0m 6s\n",
      "batch: 400/1875 - train loss: 12.5674 - test loss: 12.3133 - train acc: 0.2447 - test acc: 0.2944 - 0m 8s\n",
      "batch: 500/1875 - train loss: 11.8895 - test loss: 11.2334 - train acc: 0.3166 - test acc: 0.3690 - 0m 11s\n",
      "batch: 600/1875 - train loss: 10.0118 - test loss: 8.5804 - train acc: 0.4494 - test acc: 0.5144 - 0m 14s\n",
      "batch: 700/1875 - train loss: 7.7563 - test loss: 6.8930 - train acc: 0.5113 - test acc: 0.5430 - 0m 16s\n",
      "batch: 800/1875 - train loss: 6.1511 - test loss: 5.7239 - train acc: 0.6131 - test acc: 0.6399 - 0m 19s\n",
      "batch: 900/1875 - train loss: 4.9833 - test loss: 4.6044 - train acc: 0.7041 - test acc: 0.7133 - 0m 22s\n",
      "batch: 1000/1875 - train loss: 4.5868 - test loss: 4.1337 - train acc: 0.7312 - test acc: 0.7662 - 0m 24s\n",
      "batch: 1100/1875 - train loss: 4.0447 - test loss: 3.6612 - train acc: 0.7772 - test acc: 0.7994 - 0m 27s\n",
      "batch: 1200/1875 - train loss: 3.6792 - test loss: 3.3187 - train acc: 0.7962 - test acc: 0.8200 - 0m 29s\n",
      "batch: 1300/1875 - train loss: 3.4214 - test loss: 3.0445 - train acc: 0.8149 - test acc: 0.8352 - 0m 32s\n",
      "batch: 1400/1875 - train loss: 3.1242 - test loss: 2.9820 - train acc: 0.8293 - test acc: 0.8410 - 0m 34s\n",
      "batch: 1500/1875 - train loss: 2.7764 - test loss: 2.6323 - train acc: 0.8494 - test acc: 0.8587 - 0m 37s\n",
      "batch: 1600/1875 - train loss: 2.7831 - test loss: 2.5885 - train acc: 0.8543 - test acc: 0.8590 - 0m 40s\n",
      "batch: 1700/1875 - train loss: 2.7016 - test loss: 2.5597 - train acc: 0.8634 - test acc: 0.8599 - 0m 42s\n",
      "batch: 1800/1875 - train loss: 2.6387 - test loss: 2.3800 - train acc: 0.8603 - test acc: 0.8737 - 0m 45s\n",
      "batch: 1875/1875 - train loss: 2.4320 - test loss: 2.3504 - train acc: 0.8709 - test acc: 0.8772 - 0m 48s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 2/10\n",
      "batch: 100/1875 - train loss: 2.3325 - test loss: 2.3190 - train acc: 0.8831 - test acc: 0.8777 - 0m 50s\n",
      "batch: 200/1875 - train loss: 2.5181 - test loss: 2.2706 - train acc: 0.8725 - test acc: 0.8799 - 0m 53s\n",
      "batch: 300/1875 - train loss: 2.2747 - test loss: 2.1538 - train acc: 0.8847 - test acc: 0.8862 - 0m 55s\n",
      "batch: 400/1875 - train loss: 2.3444 - test loss: 2.1026 - train acc: 0.8829 - test acc: 0.8910 - 0m 58s\n",
      "batch: 500/1875 - train loss: 2.0364 - test loss: 2.0677 - train acc: 0.8901 - test acc: 0.8955 - 1m 0s\n",
      "batch: 600/1875 - train loss: 2.3500 - test loss: 2.0296 - train acc: 0.8794 - test acc: 0.8957 - 1m 3s\n",
      "batch: 700/1875 - train loss: 2.0952 - test loss: 2.0178 - train acc: 0.8932 - test acc: 0.8932 - 1m 5s\n",
      "batch: 800/1875 - train loss: 2.0813 - test loss: 1.9905 - train acc: 0.8951 - test acc: 0.8967 - 1m 8s\n",
      "batch: 900/1875 - train loss: 2.1105 - test loss: 1.9330 - train acc: 0.8939 - test acc: 0.9020 - 1m 11s\n",
      "batch: 1000/1875 - train loss: 1.8768 - test loss: 1.9392 - train acc: 0.9013 - test acc: 0.9010 - 1m 13s\n",
      "batch: 1100/1875 - train loss: 2.1503 - test loss: 2.0001 - train acc: 0.8872 - test acc: 0.8966 - 1m 16s\n",
      "batch: 1200/1875 - train loss: 2.1204 - test loss: 1.9175 - train acc: 0.8907 - test acc: 0.9007 - 1m 19s\n",
      "batch: 1300/1875 - train loss: 2.1599 - test loss: 1.9218 - train acc: 0.8888 - test acc: 0.9002 - 1m 22s\n",
      "batch: 1400/1875 - train loss: 2.1337 - test loss: 1.9332 - train acc: 0.8876 - test acc: 0.8997 - 1m 24s\n",
      "batch: 1500/1875 - train loss: 1.9395 - test loss: 1.9003 - train acc: 0.8979 - test acc: 0.9008 - 1m 27s\n",
      "batch: 1600/1875 - train loss: 1.9337 - test loss: 1.9163 - train acc: 0.9048 - test acc: 0.9004 - 1m 29s\n",
      "batch: 1700/1875 - train loss: 2.0244 - test loss: 1.8141 - train acc: 0.9020 - test acc: 0.9053 - 1m 32s\n",
      "batch: 1800/1875 - train loss: 2.1097 - test loss: 1.7945 - train acc: 0.8875 - test acc: 0.9054 - 1m 34s\n",
      "batch: 1875/1875 - train loss: 1.8837 - test loss: 1.8306 - train acc: 0.9010 - test acc: 0.9052 - 1m 37s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 3/10\n",
      "batch: 100/1875 - train loss: 1.7417 - test loss: 1.7570 - train acc: 0.9057 - test acc: 0.9098 - 1m 39s\n",
      "batch: 200/1875 - train loss: 1.8817 - test loss: 1.7977 - train acc: 0.9044 - test acc: 0.9071 - 1m 42s\n",
      "batch: 300/1875 - train loss: 1.9423 - test loss: 1.7934 - train acc: 0.8988 - test acc: 0.9063 - 1m 45s\n",
      "batch: 400/1875 - train loss: 1.8295 - test loss: 1.7828 - train acc: 0.9107 - test acc: 0.9054 - 1m 48s\n",
      "batch: 500/1875 - train loss: 1.9077 - test loss: 1.6770 - train acc: 0.9091 - test acc: 0.9135 - 1m 50s\n",
      "batch: 600/1875 - train loss: 1.7419 - test loss: 1.7474 - train acc: 0.9154 - test acc: 0.9083 - 1m 53s\n",
      "batch: 700/1875 - train loss: 1.7443 - test loss: 1.6840 - train acc: 0.9088 - test acc: 0.9124 - 1m 56s\n",
      "batch: 800/1875 - train loss: 1.7302 - test loss: 1.7225 - train acc: 0.9099 - test acc: 0.9114 - 1m 58s\n",
      "batch: 900/1875 - train loss: 1.6797 - test loss: 1.7189 - train acc: 0.9158 - test acc: 0.9111 - 2m 1s\n",
      "batch: 1000/1875 - train loss: 1.8122 - test loss: 1.6780 - train acc: 0.9102 - test acc: 0.9097 - 2m 3s\n",
      "batch: 1100/1875 - train loss: 1.6475 - test loss: 1.6071 - train acc: 0.9173 - test acc: 0.9164 - 2m 6s\n",
      "batch: 1200/1875 - train loss: 1.7100 - test loss: 1.6172 - train acc: 0.9070 - test acc: 0.9152 - 2m 9s\n",
      "batch: 1300/1875 - train loss: 1.5296 - test loss: 1.6541 - train acc: 0.9173 - test acc: 0.9166 - 2m 11s\n",
      "batch: 1400/1875 - train loss: 1.7776 - test loss: 1.5605 - train acc: 0.9054 - test acc: 0.9200 - 2m 14s\n",
      "batch: 1500/1875 - train loss: 1.6214 - test loss: 1.5826 - train acc: 0.9142 - test acc: 0.9163 - 2m 16s\n",
      "batch: 1600/1875 - train loss: 1.8561 - test loss: 1.6264 - train acc: 0.9067 - test acc: 0.9148 - 2m 19s\n",
      "batch: 1700/1875 - train loss: 1.7176 - test loss: 1.5656 - train acc: 0.9201 - test acc: 0.9177 - 2m 22s\n",
      "batch: 1800/1875 - train loss: 1.5536 - test loss: 1.5127 - train acc: 0.9195 - test acc: 0.9222 - 2m 24s\n",
      "batch: 1875/1875 - train loss: 1.6842 - test loss: 1.5311 - train acc: 0.9114 - test acc: 0.9214 - 2m 27s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 4/10\n",
      "batch: 100/1875 - train loss: 1.6096 - test loss: 1.5475 - train acc: 0.9167 - test acc: 0.9214 - 2m 30s\n",
      "batch: 200/1875 - train loss: 1.3862 - test loss: 1.4905 - train acc: 0.9286 - test acc: 0.9239 - 2m 32s\n",
      "batch: 300/1875 - train loss: 1.5685 - test loss: 1.4790 - train acc: 0.9183 - test acc: 0.9254 - 2m 34s\n",
      "batch: 400/1875 - train loss: 1.5162 - test loss: 1.5642 - train acc: 0.9198 - test acc: 0.9202 - 2m 37s\n",
      "batch: 500/1875 - train loss: 1.5771 - test loss: 1.5486 - train acc: 0.9191 - test acc: 0.9177 - 2m 40s\n",
      "batch: 600/1875 - train loss: 1.5269 - test loss: 1.6479 - train acc: 0.9201 - test acc: 0.9132 - 2m 42s\n",
      "batch: 700/1875 - train loss: 1.7151 - test loss: 1.4338 - train acc: 0.9135 - test acc: 0.9241 - 2m 45s\n",
      "batch: 800/1875 - train loss: 1.3900 - test loss: 1.4831 - train acc: 0.9299 - test acc: 0.9238 - 2m 47s\n",
      "batch: 900/1875 - train loss: 1.4908 - test loss: 1.4534 - train acc: 0.9245 - test acc: 0.9245 - 2m 50s\n",
      "batch: 1000/1875 - train loss: 1.5180 - test loss: 1.4382 - train acc: 0.9211 - test acc: 0.9246 - 2m 53s\n",
      "batch: 1100/1875 - train loss: 1.4617 - test loss: 1.4397 - train acc: 0.9239 - test acc: 0.9272 - 2m 56s\n",
      "batch: 1200/1875 - train loss: 1.3831 - test loss: 1.3857 - train acc: 0.9314 - test acc: 0.9293 - 2m 58s\n",
      "batch: 1300/1875 - train loss: 1.5420 - test loss: 1.4178 - train acc: 0.9264 - test acc: 0.9293 - 3m 1s\n",
      "batch: 1400/1875 - train loss: 1.4207 - test loss: 1.3667 - train acc: 0.9267 - test acc: 0.9280 - 3m 3s\n",
      "batch: 1500/1875 - train loss: 1.2892 - test loss: 1.4780 - train acc: 0.9324 - test acc: 0.9240 - 3m 6s\n",
      "batch: 1600/1875 - train loss: 1.4015 - test loss: 1.3389 - train acc: 0.9270 - test acc: 0.9332 - 3m 8s\n",
      "batch: 1700/1875 - train loss: 1.5125 - test loss: 1.4390 - train acc: 0.9245 - test acc: 0.9245 - 3m 11s\n",
      "batch: 1800/1875 - train loss: 1.3600 - test loss: 1.3518 - train acc: 0.9333 - test acc: 0.9295 - 3m 14s\n",
      "batch: 1875/1875 - train loss: 1.5058 - test loss: 1.3365 - train acc: 0.9264 - test acc: 0.9310 - 3m 16s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 5/10\n",
      "batch: 100/1875 - train loss: 1.4248 - test loss: 1.4735 - train acc: 0.9292 - test acc: 0.9211 - 3m 19s\n",
      "batch: 200/1875 - train loss: 1.3035 - test loss: 1.4410 - train acc: 0.9317 - test acc: 0.9276 - 3m 21s\n",
      "batch: 300/1875 - train loss: 1.3009 - test loss: 1.3304 - train acc: 0.9348 - test acc: 0.9309 - 3m 24s\n",
      "batch: 400/1875 - train loss: 1.3258 - test loss: 1.3351 - train acc: 0.9298 - test acc: 0.9314 - 3m 27s\n",
      "batch: 500/1875 - train loss: 1.5199 - test loss: 1.4822 - train acc: 0.9245 - test acc: 0.9204 - 3m 30s\n",
      "batch: 600/1875 - train loss: 1.3578 - test loss: 1.3741 - train acc: 0.9273 - test acc: 0.9275 - 3m 32s\n",
      "batch: 700/1875 - train loss: 1.2661 - test loss: 1.3881 - train acc: 0.9370 - test acc: 0.9274 - 3m 35s\n",
      "batch: 800/1875 - train loss: 1.4316 - test loss: 1.2595 - train acc: 0.9326 - test acc: 0.9344 - 3m 37s\n",
      "batch: 900/1875 - train loss: 1.3159 - test loss: 1.3587 - train acc: 0.9286 - test acc: 0.9312 - 3m 40s\n",
      "batch: 1000/1875 - train loss: 1.3656 - test loss: 1.2416 - train acc: 0.9280 - test acc: 0.9331 - 3m 42s\n",
      "batch: 1100/1875 - train loss: 1.2039 - test loss: 1.2431 - train acc: 0.9386 - test acc: 0.9349 - 3m 45s\n",
      "batch: 1200/1875 - train loss: 1.2717 - test loss: 1.2668 - train acc: 0.9345 - test acc: 0.9360 - 3m 48s\n",
      "batch: 1300/1875 - train loss: 1.1888 - test loss: 1.2438 - train acc: 0.9414 - test acc: 0.9349 - 3m 50s\n",
      "batch: 1400/1875 - train loss: 1.2876 - test loss: 1.2449 - train acc: 0.9377 - test acc: 0.9347 - 3m 53s\n",
      "batch: 1500/1875 - train loss: 1.3084 - test loss: 1.2415 - train acc: 0.9327 - test acc: 0.9372 - 3m 56s\n",
      "batch: 1600/1875 - train loss: 1.2551 - test loss: 1.2732 - train acc: 0.9348 - test acc: 0.9348 - 3m 59s\n",
      "batch: 1700/1875 - train loss: 1.3409 - test loss: 1.2892 - train acc: 0.9329 - test acc: 0.9327 - 4m 1s\n",
      "batch: 1800/1875 - train loss: 1.1566 - test loss: 1.3123 - train acc: 0.9379 - test acc: 0.9335 - 4m 4s\n",
      "batch: 1875/1875 - train loss: 1.2666 - test loss: 1.2426 - train acc: 0.9380 - test acc: 0.9365 - 4m 6s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 6/10\n",
      "batch: 100/1875 - train loss: 1.1865 - test loss: 1.2661 - train acc: 0.9392 - test acc: 0.9344 - 4m 9s\n",
      "batch: 200/1875 - train loss: 1.2735 - test loss: 1.2278 - train acc: 0.9355 - test acc: 0.9391 - 4m 11s\n",
      "batch: 300/1875 - train loss: 1.3173 - test loss: 1.2082 - train acc: 0.9358 - test acc: 0.9369 - 4m 14s\n",
      "batch: 400/1875 - train loss: 1.2050 - test loss: 1.2318 - train acc: 0.9420 - test acc: 0.9336 - 4m 17s\n",
      "batch: 500/1875 - train loss: 1.1753 - test loss: 1.2684 - train acc: 0.9439 - test acc: 0.9314 - 4m 19s\n",
      "batch: 600/1875 - train loss: 1.1401 - test loss: 1.1801 - train acc: 0.9430 - test acc: 0.9392 - 4m 22s\n",
      "batch: 700/1875 - train loss: 1.2670 - test loss: 1.1997 - train acc: 0.9386 - test acc: 0.9385 - 4m 24s\n",
      "batch: 800/1875 - train loss: 1.0269 - test loss: 1.1886 - train acc: 0.9450 - test acc: 0.9395 - 4m 27s\n",
      "batch: 900/1875 - train loss: 1.2570 - test loss: 1.1968 - train acc: 0.9374 - test acc: 0.9359 - 4m 30s\n",
      "batch: 1000/1875 - train loss: 1.2360 - test loss: 1.2065 - train acc: 0.9364 - test acc: 0.9378 - 4m 33s\n",
      "batch: 1100/1875 - train loss: 1.1858 - test loss: 1.2278 - train acc: 0.9395 - test acc: 0.9358 - 4m 35s\n",
      "batch: 1200/1875 - train loss: 1.2155 - test loss: 1.2458 - train acc: 0.9367 - test acc: 0.9343 - 4m 37s\n",
      "batch: 1300/1875 - train loss: 1.2330 - test loss: 1.2139 - train acc: 0.9402 - test acc: 0.9392 - 4m 40s\n",
      "batch: 1400/1875 - train loss: 1.1985 - test loss: 1.2297 - train acc: 0.9377 - test acc: 0.9365 - 4m 43s\n",
      "batch: 1500/1875 - train loss: 1.1826 - test loss: 1.2502 - train acc: 0.9374 - test acc: 0.9317 - 4m 45s\n",
      "batch: 1600/1875 - train loss: 1.2002 - test loss: 1.1800 - train acc: 0.9439 - test acc: 0.9375 - 4m 48s\n",
      "batch: 1700/1875 - train loss: 1.0894 - test loss: 1.1279 - train acc: 0.9440 - test acc: 0.9391 - 4m 51s\n",
      "batch: 1800/1875 - train loss: 1.0751 - test loss: 1.1842 - train acc: 0.9446 - test acc: 0.9369 - 4m 53s\n",
      "batch: 1875/1875 - train loss: 1.1419 - test loss: 1.1650 - train acc: 0.9414 - test acc: 0.9412 - 4m 55s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "starting epoch: 7/10\n",
      "batch: 100/1875 - train loss: 0.9185 - test loss: 1.1211 - train acc: 0.9564 - test acc: 0.9418 - 4m 58s\n",
      "time is up! finishing training\n",
      "batch: 137/1875 - train loss: 1.0635 - test loss: 1.1971 - train acc: 0.9492 - test acc: 0.9383 - 5m 1s\n",
      "GPU memory used: 0.01 GB - max: 0.02 GB - memory reserved: 0.02 GB - max: 0.02 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buffer_size = 64\n",
    "partition_size = 32\n",
    "# block_updates = 1024\n",
    "\n",
    "results_list = []\n",
    "step_i = 0\n",
    "\n",
    "for i, block_updates in enumerate([2, 8, 32, 128, 512, 2048]):\n",
    "        \n",
    "    print()\n",
    "    print('-----------------------------------')\n",
    "    print(f'testing: partition-size: {partition_size} - buffer-size: {buffer_size} - block_updates: {block_updates}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    default_metrics, _, _ = train_network_fisher_optimization(apply_fisher = True,\n",
    "                                                           buffer_size = buffer_size,\n",
    "                                                           partition_size = partition_size,\n",
    "                                                           block_updates = block_updates,\n",
    "                                                           epochs = 10,\n",
    "                                                           time_limit_secs = 5 * 60)\n",
    "    \n",
    "    results_list.append( (default_metrics, buffer_size, partition_size, block_updates) )\n",
    "    results_list_to_json(results_list, step=step_i)\n",
    "    step_i += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01582331",
   "metadata": {
    "papermill": {
     "duration": 0.053232,
     "end_time": "2022-10-07T05:32:10.612857",
     "exception": false,
     "start_time": "2022-10-07T05:32:10.559625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1864.747723,
   "end_time": "2022-10-07T05:32:14.390371",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-07T05:01:09.642648",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "041963780b644974b6112ec113c06287": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8ebdfb60ffeb4ea19f51b0e92a1d6e47",
        "IPY_MODEL_6bd3a32f6d9b40ff817adedd1db6af98",
        "IPY_MODEL_fa6f3cca25e44375b49caf85e77ac6a0"
       ],
       "layout": "IPY_MODEL_19f58f72f34e4ef9a05a2cf1b113dde6"
      }
     },
     "08265d790c2c4080a202863ed7f21e87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bcc883bebee4c6aa203b15676c0fb7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "108b070c1e264f58ab367b23e4c9bdf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "160b937512774dc19782c4295738cb27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1631a5b396d74ecf94350ebd237ab3c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bd19f0b867924995a9020a58507427fc",
       "placeholder": "​",
       "style": "IPY_MODEL_6a1f36a0042f4c5fb0a2b91dc0222417",
       "value": " 5120/? [00:00&lt;00:00, 172395.87it/s]"
      }
     },
     "174db707110f49569d41ca94a1d5868c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_277220a85e374b308d04ea5fc599c04d",
       "placeholder": "​",
       "style": "IPY_MODEL_7cd34674ff6a4e9bb1f125232749813d",
       "value": ""
      }
     },
     "19f58f72f34e4ef9a05a2cf1b113dde6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23228848aa874c4183086c5fca81bd3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "258725336e4d47c6866db284e279e1f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27478b1271584222bd378dd9d932784b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "277220a85e374b308d04ea5fc599c04d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2af686e0ba5b4e95919c099ca2feaafa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "309a6f61c2494ddeadc2e7f681cd1820": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f0611068ae74e0c9ed82682345a99a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4a099cc670e14d659a8f6ceb8462320c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "512584929c4c440e8a907d5b2147a4c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_76ec36d0e60f422d8d77e4d46461bc77",
       "placeholder": "​",
       "style": "IPY_MODEL_27478b1271584222bd378dd9d932784b",
       "value": ""
      }
     },
     "57356a4dd6e4431ea42284823a834686": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ba96a9a15494d2fa35e5f77754a6ddf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "61ffae8cbcbb40bc8b15069da67e70f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a1f36a0042f4c5fb0a2b91dc0222417": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6bd3a32f6d9b40ff817adedd1db6af98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_309a6f61c2494ddeadc2e7f681cd1820",
       "max": 28881,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e86e7d09f95b41318d8877da6dce0fef",
       "value": 28881
      }
     },
     "6c1aca1c977246c0a75edf5c2a2ec8c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6c63573449ab453eb0d8b055941b1a0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eade200d272c4c2a87a6fe7a57d182ef",
        "IPY_MODEL_a776cc64e557499f8600daa216d09dfe",
        "IPY_MODEL_1631a5b396d74ecf94350ebd237ab3c2"
       ],
       "layout": "IPY_MODEL_258725336e4d47c6866db284e279e1f3"
      }
     },
     "76ec36d0e60f422d8d77e4d46461bc77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cd34674ff6a4e9bb1f125232749813d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "81b45f8b7f3f4e39ae6c95ed8886d028": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82509cff1c1242e6b511bdde2d73059f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83c4fe69f79246f6ad63ae5223067148": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2af686e0ba5b4e95919c099ca2feaafa",
       "max": 9912422,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f7f03429be364aab9d1dc215c0e5dbf9",
       "value": 9912422
      }
     },
     "8846f908fb4f4f849959e76fc504c779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_08265d790c2c4080a202863ed7f21e87",
       "max": 1648877,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_108b070c1e264f58ab367b23e4c9bdf9",
       "value": 1648877
      }
     },
     "8ebdfb60ffeb4ea19f51b0e92a1d6e47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81b45f8b7f3f4e39ae6c95ed8886d028",
       "placeholder": "​",
       "style": "IPY_MODEL_160b937512774dc19782c4295738cb27",
       "value": ""
      }
     },
     "8fd58a9324f74204aac0210a7afa9e42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_174db707110f49569d41ca94a1d5868c",
        "IPY_MODEL_83c4fe69f79246f6ad63ae5223067148",
        "IPY_MODEL_a4ed7875981c48618e5513f551c9d437"
       ],
       "layout": "IPY_MODEL_9d365e2f612e4ba8862cc3ea75abda97"
      }
     },
     "9d365e2f612e4ba8862cc3ea75abda97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e5a6db7c51044028e99bb67afd0eda1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4ed7875981c48618e5513f551c9d437": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_82509cff1c1242e6b511bdde2d73059f",
       "placeholder": "​",
       "style": "IPY_MODEL_5ba96a9a15494d2fa35e5f77754a6ddf",
       "value": " 9913344/? [00:00&lt;00:00, 30064095.24it/s]"
      }
     },
     "a776cc64e557499f8600daa216d09dfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23228848aa874c4183086c5fca81bd3f",
       "max": 4542,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6c1aca1c977246c0a75edf5c2a2ec8c8",
       "value": 4542
      }
     },
     "bd19f0b867924995a9020a58507427fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c213a3b0c47143da97062f2bc3ab638e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deff27fa5f734ac99ebd837eff95b8e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_57356a4dd6e4431ea42284823a834686",
       "placeholder": "​",
       "style": "IPY_MODEL_3f0611068ae74e0c9ed82682345a99a4",
       "value": " 1649664/? [00:00&lt;00:00, 8417047.21it/s]"
      }
     },
     "e86e7d09f95b41318d8877da6dce0fef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eade200d272c4c2a87a6fe7a57d182ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_61ffae8cbcbb40bc8b15069da67e70f5",
       "placeholder": "​",
       "style": "IPY_MODEL_4a099cc670e14d659a8f6ceb8462320c",
       "value": ""
      }
     },
     "f4b5ecc4fb814edb8524e54c36f61539": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_512584929c4c440e8a907d5b2147a4c1",
        "IPY_MODEL_8846f908fb4f4f849959e76fc504c779",
        "IPY_MODEL_deff27fa5f734ac99ebd837eff95b8e9"
       ],
       "layout": "IPY_MODEL_9e5a6db7c51044028e99bb67afd0eda1"
      }
     },
     "f7f03429be364aab9d1dc215c0e5dbf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fa6f3cca25e44375b49caf85e77ac6a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c213a3b0c47143da97062f2bc3ab638e",
       "placeholder": "​",
       "style": "IPY_MODEL_0bcc883bebee4c6aa203b15676c0fb7b",
       "value": " 29696/? [00:00&lt;00:00, 954722.50it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
